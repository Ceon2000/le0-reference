{
  "input": "Review the codebase in fixtures/helpdesk_ai/ and identify any bugs or issues. The complete codebase will be provided in the expanded input.\n\n===== FIXTURE CODEBASE =====\n\nThe following is the complete codebase from fixtures/helpdesk_ai/:\n\n===== FILE: pyproject.toml =====\n[project]\nname = \"helpdesk-ai\"\nversion = \"0.1.0\"\ndescription = \"Helpdesk triage service with AI-assisted routing\"\nrequires-python = \">=3.9\"\ndependencies = []\n\n[project.optional-dependencies]\ndev = []\n\n[tool.pytest.ini_options]\ntestpaths = [\"tests\"]\npython_files = \"test_*.py\"\npython_classes = \"Test*\"\npython_functions = \"test_*\"\n\n\n\n===== FILE: README.md =====\n# Helpdesk AI Triage Service\n\nA helpdesk ticket triage and routing service that uses rule-based scoring and priority assignment to automatically route tickets to appropriate teams.\n\n## Overview\n\nThe Helpdesk AI service processes incoming tickets, scores them based on priority and urgency indicators, matches them against routing rules, and assigns them to appropriate teams. The system includes components for data ingestion, validation, normalization, storage, caching, routing, triage, and escalation.\n\n## Architecture\n\nThe service is organized into several key modules:\n\n- **Domain**: Core business logic including ticket models, rule engine, and scoring system\n- **Ingest**: Data parsing, normalization, and validation\n- **Store**: Storage backends (memory and file-based) with caching\n- **Services**: Triage, routing, escalation, and audit services\n- **Utils**: Utility functions for text processing, time handling, and ID generation\n- **Web**: Minimal web interface skeleton\n- **CLI**: Command-line interface for processing tickets\n\n## Key Features\n\n- Multi-format ticket parsing (JSON, CSV, plain text)\n- Rule-based routing with priority matching\n- Weighted scoring system for ticket prioritization\n- Automatic escalation based on age and priority\n- Audit logging for all ticket operations\n- Configurable storage backends\n- Caching layer for performance optimization\n\n## Usage\n\n### CLI Usage\n\nProcess a ticket file:\n\n```bash\npython -m helpdesk_ai.cli input.json output.json\n```\n\n### Programmatic Usage\n\n```python\nfrom helpdesk_ai.domain.models import Ticket, Category, Priority\nfrom helpdesk_ai.services.triage import TriageService\nfrom helpdesk_ai.cli import create_default_triage_service\n\n# Create triage service\ntriage_service = create_default_triage_service()\n\n# Create a ticket\nticket = Ticket(\n    ticket_id=\"TKT-20240101-ABC12345\",\n    title=\"Payment issue\",\n    description=\"Unable to process payment\",\n    requester_email=\"user@example.com\",\n    category=Category.BILLING,\n    priority=Priority.HIGH,\n)\n\n# Triage the ticket\nresult = triage_service.triage(ticket)\nprint(f\"Assigned to: {result.assigned_to}\")\nprint(f\"Priority: {result.priority}\")\n```\n\n## Configuration\n\nConfiguration can be provided via environment variables or a config file:\n\n- `HELPDESK_STORE_TYPE`: Storage backend type (memory or file)\n- `HELPDESK_STORE_PATH`: Path for file-based storage\n- `HELPDESK_CACHE_ENABLED`: Enable/disable caching\n- `HELPDESK_CACHE_TTL`: Cache TTL in seconds\n- `HELPDESK_ESCALATION_THRESHOLD`: Hours before auto-escalation\n- `HELPDESK_LOG_LEVEL`: Logging level\n\n## Testing\n\nRun tests with pytest:\n\n```bash\npytest tests/\n```\n\n## Data Model\n\nTickets contain the following key fields:\n\n- `ticket_id`: Unique identifier\n- `title`: Ticket title/subject\n- `description`: Detailed description\n- `requester_email`: Requester's email address\n- `category`: Ticket category (technical, billing, account, etc.)\n- `priority`: Priority level (critical, high, medium, low)\n- `status`: Current status (new, triaged, assigned, etc.)\n- `assigned_to`: Assigned team or individual\n- `tags`: List of tags\n- `metadata`: Additional metadata dictionary\n- `score`: Calculated priority score\n\n## Routing Rules\n\nRouting rules match tickets based on conditions and assign them to appropriate teams. Rules have:\n\n- `rule_id`: Unique rule identifier\n- `name`: Human-readable rule name\n- `priority`: Priority level for matching tickets\n- `condition`: Function that determines if rule matches\n- `target_category`: Category to assign\n- `target_assignee`: Team or individual to assign to\n\n## Scoring\n\nThe scoring system combines multiple factors:\n\n- Priority-based scoring (critical=10, high=7, medium=4, low=1)\n- Urgency keyword matching in title/description\n- Custom weighted combinations\n\nScores are normalized to 0-1 range for consistent comparison.\n\n## Storage\n\nTwo storage backends are available:\n\n- **MemoryStore**: In-memory storage for testing and development\n- **FileStore**: File-based JSON storage for persistence\n\nBoth support CRUD operations, search, and listing.\n\n## Caching\n\nThe caching layer provides:\n\n- TTL-based expiration\n- Key-based lookups\n- Automatic cleanup of expired entries\n\nCache keys are generated from ticket attributes for efficient lookups.\n\n## Escalation\n\nAutomatic escalation occurs when:\n\n- Critical priority tickets remain unresolved\n- Tickets exceed age threshold (default 24 hours)\n\nEscalated tickets have priority increased and status set to ESCALATED.\n\n## Audit Logging\n\nAll ticket operations are logged with:\n\n- Action type\n- Actor (who performed the action)\n- Timestamp\n- Changes made\n- Additional metadata\n\nAudit logs can be queried by ticket ID, actor, or time range.\n\n\n\n===== FILE: docs\\API.md =====\n# API Documentation\n\n## CLI API\n\n### Command Line Interface\n\n```bash\npython -m helpdesk_ai.cli <input_file> [output_file]\n```\n\nProcesses a ticket file and outputs routing results.\n\n**Arguments:**\n- `input_file`: Path to input ticket file (JSON, CSV, or text)\n- `output_file`: Optional path for output JSON file\n\n**Returns:**\n- Exit code 0 on success\n- Exit code 1 on error (with error message to stderr)\n\n**Output Format:**\n```json\n{\n  \"ticket\": {\n    \"ticket_id\": \"TKT-20240101-ABC12345\",\n    \"title\": \"Ticket title\",\n    \"description\": \"Ticket description\",\n    \"requester_email\": \"user@example.com\",\n    \"category\": \"billing\",\n    \"priority\": \"high\",\n    \"status\": \"triaged\",\n    \"score\": 0.85\n  },\n  \"routing\": {\n    \"assigned_to\": \"billing-team\",\n    \"priority\": \"high\",\n    \"category\": \"billing\",\n    \"rule_matched\": \"critical_billing\",\n    \"confidence\": 1.0\n  }\n}\n```\n\n## Python API\n\n### Domain Models\n\n#### Ticket\n\n```python\nfrom helpdesk_ai.domain.models import Ticket, Category, Priority\n\nticket = Ticket(\n    ticket_id=\"TKT-20240101-ABC12345\",\n    title=\"Payment issue\",\n    description=\"Unable to process payment\",\n    requester_email=\"user@example.com\",\n    category=Category.BILLING,\n    priority=Priority.HIGH,\n)\n```\n\n#### TicketStatus Enum\n\n- `NEW`: Newly created ticket\n- `TRIAGED`: Ticket has been triaged\n- `ASSIGNED`: Ticket assigned to team\n- `IN_PROGRESS`: Work in progress\n- `RESOLVED`: Ticket resolved\n- `CLOSED`: Ticket closed\n- `ESCALATED`: Ticket escalated\n\n#### Priority Enum\n\n- `CRITICAL`: Highest priority\n- `HIGH`: High priority\n- `MEDIUM`: Medium priority\n- `LOW`: Low priority\n\n#### Category Enum\n\n- `TECHNICAL`: Technical issues\n- `BILLING`: Billing and payment\n- `ACCOUNT`: Account management\n- `FEATURE`: Feature requests\n- `BUG`: Bug reports\n- `GENERAL`: General inquiries\n\n### Storage API\n\n#### MemoryStore\n\n```python\nfrom helpdesk_ai.store.memory_store import MemoryStore\n\nstore = MemoryStore()\nstore.save(ticket)\nticket = store.get(\"TKT-20240101-ABC12345\")\ntickets = store.list_all()\nstore.delete(\"TKT-20240101-ABC12345\")\n```\n\n#### FileStore\n\n```python\nfrom helpdesk_ai.store.file_store import FileStore\n\nstore = FileStore(\"./data\")\nstore.save(ticket)\nticket = store.get(\"TKT-20240101-ABC12345\")\n```\n\n### Triage Service API\n\n```python\nfrom helpdesk_ai.services.triage import TriageService\nfrom helpdesk_ai.cli import create_default_triage_service\n\ntriage_service = create_default_triage_service()\nresult = triage_service.triage(ticket)\n```\n\n**Returns:** `RoutingResult` with:\n- `ticket`: Updated ticket object\n- `assigned_to`: Assigned team or individual\n- `priority`: Assigned priority\n- `category`: Assigned category\n- `rule_matched`: ID of matched rule (if any)\n- `confidence`: Confidence score (0.0-1.0)\n\n### Scoring API\n\n```python\nfrom helpdesk_ai.domain.scoring import PriorityScorer, UrgencyScorer, WeightedScorer\n\npriority_scorer = PriorityScorer()\nscore = priority_scorer.score(ticket)\n\nurgency_scorer = UrgencyScorer()\nscore = urgency_scorer.score(ticket)\n\nscorer = WeightedScorer(\n    scorers={\n        \"priority\": priority_scorer.score,\n        \"urgency\": urgency_scorer.score,\n    },\n    weights={\"priority\": 0.6, \"urgency\": 0.4},\n    normalize=True,\n)\nscore = scorer.score(ticket)\n```\n\n**Score Object:**\n- `total`: Total weighted score\n- `components`: Dictionary of component scores\n- `normalized`: Normalized score (0.0-1.0) if normalization enabled\n\n### Rule Engine API\n\n```python\nfrom helpdesk_ai.domain.rules import RuleEngine, Rule\nfrom helpdesk_ai.domain.models import Priority, Category\n\nrule_engine = RuleEngine()\n\nrule = Rule(\n    rule_id=\"critical_billing\",\n    name=\"Critical Billing Issues\",\n    priority=Priority.CRITICAL,\n    condition=lambda t: t.category == Category.BILLING and \"payment\" in t.description.lower(),\n    target_category=Category.BILLING,\n    target_assignee=\"billing-team\",\n)\n\nrule_engine.add_rule(rule)\nmatches = rule_engine.evaluate(ticket)\nmatching_rule = rule_engine.get_highest_priority_match(ticket)\n```\n\n### Escalation Service API\n\n```python\nfrom helpdesk_ai.services.escalation import EscalationService\n\nescalation_service = EscalationService(\n    escalation_threshold_hours=24,\n    auto_escalate_critical=True,\n)\n\nif escalation_service.should_escalate(ticket):\n    escalated_ticket = escalation_service.escalate(ticket, reason=\"Age threshold exceeded\")\n```\n\n### Audit Service API\n\n```python\nfrom helpdesk_ai.services.audit import AuditService\n\naudit_service = AuditService()\naudit_service.log(\n    ticket_id=\"TKT-20240101-ABC12345\",\n    action=\"update\",\n    actor=\"system\",\n    changes={\"priority\": \"high\"},\n)\n\nlogs = audit_service.get_logs_for_ticket(\"TKT-20240101-ABC12345\")\n```\n\n### Configuration API\n\n```python\nfrom helpdesk_ai.config import Config\n\nconfig = Config(config_file=\"./config.json\")\nstore_type = config.get(\"store_type\", \"memory\")\nconfig.set(\"cache_enabled\", True)\nconfig.save_to_file()\n```\n\n### Parser API\n\n```python\nfrom helpdesk_ai.ingest.parsers import JSONParser, CSVParser, TextParser, MultiFormatParser\n\nparser = JSONParser()\ndata = parser.parse(json_string)\n\nparser = MultiFormatParser()\ndata = parser.parse(any_format_string)\n```\n\n### Validator API\n\n```python\nfrom helpdesk_ai.ingest.validators import TicketValidator\n\nvalidator = TicketValidator()\nerrors = validator.validate(data_dict)\nif errors:\n    for error in errors:\n        print(f\"{error.field}: {error.message}\")\n```\n\n### Normalizer API\n\n```python\nfrom helpdesk_ai.ingest.normalize import TicketNormalizer\n\nnormalizer = TicketNormalizer()\nticket = normalizer.normalize(parsed_data_dict)\n```\n\n## Error Handling\n\nAll APIs raise appropriate exceptions:\n\n- `ValidationError`: Data validation failures\n- `StorageError`: Storage operation failures\n- `RoutingError`: Routing failures\n- `ScoringError`: Scoring failures\n- `ParsingError`: Parsing failures\n\nExceptions inherit from `HelpdeskError` base class.\n\n\n\n===== FILE: docs\\ARCHITECTURE.md =====\n# Architecture Documentation\n\n## System Overview\n\nThe Helpdesk AI Triage Service is designed as a modular system with clear separation of concerns. The architecture follows a layered approach with domain models at the core, surrounded by service layers, data access layers, and presentation layers.\n\n## Component Layers\n\n### Domain Layer\n\nThe domain layer contains core business logic and models:\n\n- **Models**: Ticket, TicketStatus, Priority, Category enums and data classes\n- **Rules**: Rule engine for matching tickets against routing rules\n- **Scoring**: Scoring algorithms for ticket prioritization\n\nThis layer is independent of infrastructure and can be tested in isolation.\n\n### Ingest Layer\n\nThe ingest layer handles data input and transformation:\n\n- **Parsers**: Convert raw input (JSON, CSV, text) into structured data\n- **Normalizers**: Transform parsed data into domain models\n- **Validators**: Ensure data quality and completeness\n\nThis layer provides a clean interface for accepting tickets from various sources.\n\n### Store Layer\n\nThe store layer abstracts data persistence:\n\n- **MemoryStore**: In-memory storage for development and testing\n- **FileStore**: File-based JSON storage for simple persistence\n- **Cache**: Caching layer for performance optimization\n\nStorage implementations are swappable, allowing different backends without changing business logic.\n\n### Service Layer\n\nThe service layer orchestrates business operations:\n\n- **TriageService**: Coordinates scoring and routing\n- **Router**: Applies routing rules to assign tickets\n- **EscalationService**: Handles automatic escalations\n- **AuditService**: Tracks all operations\n\nServices compose domain logic and storage to provide high-level operations.\n\n### Presentation Layer\n\nThe presentation layer provides interfaces for users:\n\n- **CLI**: Command-line interface for batch processing\n- **Web**: Minimal web interface skeleton\n\nThese layers are thin wrappers around service methods.\n\n## Data Flow\n\n1. **Ingestion**: Raw ticket data enters through parsers\n2. **Validation**: Validators ensure data quality\n3. **Normalization**: Normalizers convert to domain models\n4. **Scoring**: Scorers calculate priority scores\n5. **Routing**: Router applies rules to assign tickets\n6. **Storage**: Tickets are persisted to storage backend\n7. **Audit**: Operations are logged for tracking\n\n## Design Patterns\n\n### Strategy Pattern\n\nScoring uses the strategy pattern - different scorers can be plugged in:\n- PriorityScorer\n- UrgencyScorer\n- WeightedScorer (composite)\n\n### Factory Pattern\n\nService creation uses factory functions:\n- `create_default_triage_service()` creates configured service instances\n\n### Repository Pattern\n\nStorage backends implement repository pattern:\n- Abstract interface (implicit)\n- Multiple implementations (MemoryStore, FileStore)\n\n## Extension Points\n\nThe system is designed for extension:\n\n1. **New Parsers**: Implement Parser interface\n2. **New Scorers**: Implement Scorer interface\n3. **New Storage**: Implement storage interface\n4. **New Rules**: Add Rule instances to RuleEngine\n5. **New Services**: Compose existing components\n\n## Performance Considerations\n\n- Caching layer reduces repeated operations\n- In-memory storage for high-throughput scenarios\n- File storage for persistence without database overhead\n- Batch operations for processing multiple tickets\n\n## Error Handling\n\nErrors are handled at appropriate layers:\n\n- Parsing errors: Caught and reported during ingestion\n- Validation errors: Collected and returned as list\n- Storage errors: Wrapped in StorageError exceptions\n- Business logic errors: Domain-specific exceptions\n\n## Configuration Management\n\nConfiguration supports multiple sources:\n\n1. Default values (hardcoded)\n2. Config file (JSON)\n3. Environment variables (highest precedence)\n\nThis allows flexible deployment across environments.\n\n## Testing Strategy\n\n- Unit tests for individual components\n- Integration tests for service composition\n- No external dependencies (no network, no database)\n- Mock-friendly interfaces\n\n## Future Enhancements\n\nPotential areas for extension:\n\n- Database storage backend\n- Real-time web interface\n- Advanced scoring algorithms\n- Machine learning integration\n- Multi-tenant support\n- Advanced rule conditions\n\n\n\n===== FILE: docs\\DATA_MODEL.md =====\n# Data Model Documentation\n\n## Ticket Model\n\nThe Ticket model is the central entity in the system.\n\n### Fields\n\n- **ticket_id** (str): Unique identifier for the ticket\n- **title** (str): Short title or subject of the ticket\n- **description** (str): Detailed description of the issue\n- **requester_email** (str): Email address of the person requesting help\n- **category** (Category): Category classification\n- **priority** (Priority): Priority level\n- **status** (TicketStatus): Current status\n- **created_at** (datetime): Creation timestamp\n- **updated_at** (datetime): Last update timestamp\n- **assigned_to** (str, optional): Team or individual assigned\n- **tags** (List[str]): List of tags for categorization\n- **metadata** (Dict[str, Any]): Additional metadata\n- **score** (float, optional): Calculated priority score\n\n### Constraints\n\n- `ticket_id`: Required, must match pattern `^[A-Z0-9-]+$`\n- `title`: Required, max 200 characters, cannot be empty\n- `description`: Required, cannot be empty\n- `requester_email`: Required, must be valid email format\n- `category`: Required, must be valid Category enum value\n- `priority`: Defaults to MEDIUM if not specified\n- `status`: Defaults to NEW if not specified\n\n### Methods\n\n- `update(**kwargs)`: Update fields and set updated_at timestamp\n- `to_dict()`: Convert to dictionary representation\n- `from_dict(data)`: Create from dictionary representation\n\n## Category Enum\n\nCategories classify tickets by type:\n\n- **TECHNICAL**: Technical support issues\n- **BILLING**: Billing and payment issues\n- **ACCOUNT**: Account management issues\n- **FEATURE**: Feature requests\n- **BUG**: Bug reports\n- **GENERAL**: General inquiries\n\n## Priority Enum\n\nPriorities indicate urgency:\n\n- **CRITICAL**: Highest priority, immediate attention required\n- **HIGH**: High priority, urgent attention needed\n- **MEDIUM**: Medium priority, normal processing\n- **LOW**: Low priority, can be deferred\n\nPriority weights used in scoring:\n- CRITICAL: 10.0\n- HIGH: 7.0\n- MEDIUM: 4.0\n- LOW: 1.0\n\n## TicketStatus Enum\n\nStatuses track ticket lifecycle:\n\n- **NEW**: Newly created, not yet processed\n- **TRIAGED**: Processed and categorized\n- **ASSIGNED**: Assigned to a team or individual\n- **IN_PROGRESS**: Work is actively being done\n- **RESOLVED**: Issue resolved, awaiting closure\n- **CLOSED**: Ticket closed\n- **ESCALATED**: Ticket escalated for higher attention\n\n## Score Model\n\nScores represent ticket priority calculations:\n\n- **total** (float): Total weighted score\n- **components** (Dict[str, float]): Individual component scores\n- **normalized** (float, optional): Normalized score (0.0-1.0)\n\nNormalized scores allow comparison across different scoring algorithms.\n\n## RuleMatch Model\n\nRepresents a match between a ticket and a rule:\n\n- **rule_id** (str): ID of the matched rule\n- **rule_name** (str): Name of the rule\n- **matched** (bool): Whether rule matched\n- **confidence** (float): Confidence score (0.0-1.0)\n- **metadata** (Dict[str, Any]): Additional match metadata\n\n## RoutingResult Model\n\nResult of routing a ticket:\n\n- **ticket** (Ticket): Updated ticket object\n- **assigned_to** (str, optional): Assigned team or individual\n- **priority** (Priority): Assigned priority\n- **category** (Category): Assigned category\n- **rule_matched** (str, optional): ID of matched rule\n- **confidence** (float): Confidence in routing decision\n\n## AuditLog Model\n\nAudit log entry:\n\n- **log_id** (str): Unique log identifier\n- **ticket_id** (str): Related ticket ID\n- **action** (str): Action performed\n- **actor** (str): Who performed the action\n- **timestamp** (datetime): When action occurred\n- **changes** (Dict[str, Any]): Changes made\n- **metadata** (Dict[str, Any]): Additional metadata\n\n## Storage Formats\n\n### Memory Storage\n\nTickets stored in memory as Ticket objects in a dictionary keyed by ticket_id.\n\n### File Storage\n\nTickets stored as JSON files:\n- Filename: `{ticket_id}.json`\n- Format: JSON with ISO timestamp strings\n- Location: `{base_path}/tickets/`\n\n### Cache Storage\n\nCache entries stored with:\n- Key: Generated from attributes\n- Value: Cached object\n- TTL: Time-to-live in seconds\n- Expiration: Calculated from creation time + TTL\n\n## Data Flow\n\n1. **Input**: Raw data (JSON, CSV, text)\n2. **Parse**: Convert to dictionary\n3. **Validate**: Check constraints\n4. **Normalize**: Convert to Ticket model\n5. **Score**: Calculate priority score\n6. **Route**: Apply routing rules\n7. **Store**: Persist to storage backend\n8. **Audit**: Log operation\n\n## Validation Rules\n\n### Ticket ID\n- Pattern: `^[A-Z0-9-]+$`\n- Required: Yes\n- Type: String\n\n### Title\n- Required: Yes\n- Type: String\n- Min length: 1\n- Max length: 200\n- Cannot be empty after trimming\n\n### Description\n- Required: Yes\n- Type: String\n- Min length: 1\n- Cannot be empty after trimming\n\n### Email\n- Required: Yes\n- Type: String\n- Pattern: `^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$`\n\n### Category\n- Required: Yes\n- Type: Category enum\n- Valid values: TECHNICAL, BILLING, ACCOUNT, FEATURE, BUG, GENERAL\n\n### Priority\n- Required: No (defaults to MEDIUM)\n- Type: Priority enum\n- Valid values: CRITICAL, HIGH, MEDIUM, LOW\n\n## Serialization\n\nTickets can be serialized to/from dictionaries:\n\n- `to_dict()`: Convert Ticket to dictionary\n- `from_dict(data)`: Create Ticket from dictionary\n\nDictionary format uses string values for enums and ISO format for timestamps.\n\n## Extensibility\n\nThe metadata field allows storing additional data without schema changes:\n\n```python\nticket.metadata[\"custom_field\"] = \"value\"\nticket.metadata[\"nested\"] = {\"key\": \"value\"}\n```\n\nThis enables integration with external systems and custom workflows.\n\n\n\n===== FILE: docs\\DECISIONS.md =====\n# Architecture Decisions\n\n## Decision Log\n\nThis document records key architectural decisions and their rationale.\n\n## ADR-001: Domain-Driven Design\n\n**Decision**: Organize codebase using domain-driven design principles.\n\n**Rationale**: \n- Clear separation between business logic and infrastructure\n- Domain models are independent and testable\n- Services compose domain logic without coupling to storage\n\n**Alternatives Considered**:\n- Anemic domain model (data classes only)\n- Service-oriented architecture without domain layer\n\n**Consequences**:\n- More files and structure\n- Clearer boundaries and responsibilities\n- Easier to test business logic\n\n## ADR-002: Multiple Storage Backends\n\n**Decision**: Support both in-memory and file-based storage.\n\n**Rationale**:\n- In-memory for testing and development\n- File-based for simple persistence without database\n- Swappable implementations allow future database backend\n\n**Alternatives Considered**:\n- Single storage implementation\n- Database-only approach\n\n**Consequences**:\n- More code to maintain\n- Flexibility for different use cases\n- No database dependency for simple deployments\n\n## ADR-003: Rule-Based Routing\n\n**Decision**: Use rule engine for ticket routing.\n\n**Rationale**:\n- Flexible and configurable routing logic\n- Rules can be added/modified without code changes\n- Clear separation of routing logic from business logic\n\n**Alternatives Considered**:\n- Hardcoded routing logic\n- Machine learning-based routing\n\n**Consequences**:\n- More flexible but requires rule definition\n- Rules must be maintained\n- Performance overhead of rule evaluation\n\n## ADR-004: Weighted Scoring System\n\n**Decision**: Use composable weighted scoring system.\n\n**Rationale**:\n- Multiple factors can influence priority\n- Weights can be adjusted without code changes\n- Normalized scores enable comparison\n\n**Alternatives Considered**:\n- Single-factor scoring\n- Fixed scoring algorithm\n\n**Consequences**:\n- More flexible but more complex\n- Requires weight tuning\n- Normalization must handle edge cases\n\n## ADR-005: Minimal Web Interface\n\n**Decision**: Provide minimal web interface skeleton.\n\n**Rationale**:\n- Demonstrates integration pattern\n- Keeps dependencies minimal\n- Can be extended with full web framework\n\n**Alternatives Considered**:\n- Full web framework (Flask, FastAPI)\n- No web interface\n\n**Consequences**:\n- Not production-ready\n- Easy to extend\n- Minimal dependencies\n\n## ADR-006: Standard Library Focus\n\n**Decision**: Prefer standard library over external dependencies.\n\n**Rationale**:\n- Fewer dependencies to manage\n- Faster installation\n- More portable\n\n**Alternatives Considered**:\n- Rich dependency ecosystem\n- Framework-based approach\n\n**Consequences**:\n- More code to write\n- Less functionality out of box\n- Better control over implementation\n\n## ADR-007: Configuration Precedence\n\n**Decision**: Environment variables override config file.\n\n**Rationale**:\n- Standard practice for 12-factor apps\n- Allows runtime configuration\n- Supports containerized deployments\n\n**Alternatives Considered**:\n- Config file only\n- Code-based configuration only\n\n**Consequences**:\n- Must handle precedence correctly\n- Can be confusing if not documented\n- Flexible deployment options\n\n## ADR-008: Audit Logging\n\n**Decision**: Include audit service for tracking operations.\n\n**Rationale**:\n- Compliance and debugging needs\n- Track all ticket changes\n- Support for accountability\n\n**Alternatives Considered**:\n- No audit logging\n- External audit system\n\n**Consequences**:\n- Additional storage requirements\n- Performance overhead\n- Better traceability\n\n## ADR-009: Multi-Format Parsing\n\n**Decision**: Support multiple input formats (JSON, CSV, text).\n\n**Rationale**:\n- Flexibility in data sources\n- Easy integration with various systems\n- Progressive enhancement (start simple, add formats)\n\n**Alternatives Considered**:\n- JSON only\n- Single format parser\n\n**Consequences**:\n- More parsing code\n- Format detection complexity\n- Broader compatibility\n\n## ADR-010: Caching Layer\n\n**Decision**: Include caching abstraction.\n\n**Rationale**:\n- Performance optimization\n- Reduces repeated operations\n- Can be extended with Redis or similar\n\n**Alternatives Considered**:\n- No caching\n- Hardcoded caching logic\n\n**Consequences**:\n- Additional complexity\n- Cache invalidation concerns\n- Performance benefits\n\n## Future Decisions\n\nPotential future decisions to consider:\n\n- Database storage backend selection\n- Web framework choice for production\n- Authentication and authorization approach\n- API versioning strategy\n- Monitoring and observability tools\n- Deployment architecture\n\n\n\n===== FILE: docs\\RUNBOOK.md =====\n# Runbook\n\n## Operations Guide\n\nThis runbook provides procedures for common operational tasks.\n\n## Starting the Service\n\n### CLI Mode\n\n```bash\npython -m helpdesk_ai.cli input.json output.json\n```\n\n### Programmatic Usage\n\n```python\nfrom helpdesk_ai.cli import create_default_triage_service\n\ntriage_service = create_default_triage_service()\n```\n\n## Configuration\n\n### Environment Variables\n\nSet these environment variables before starting:\n\n```bash\nexport HELPDESK_STORE_TYPE=file\nexport HELPDESK_STORE_PATH=/var/lib/helpdesk\nexport HELPDESK_CACHE_ENABLED=true\nexport HELPDESK_CACHE_TTL=3600\nexport HELPDESK_ESCALATION_THRESHOLD=24\nexport HELPDESK_LOG_LEVEL=INFO\n```\n\n### Config File\n\nCreate `config.json`:\n\n```json\n{\n  \"store_type\": \"file\",\n  \"store_path\": \"/var/lib/helpdesk\",\n  \"cache_enabled\": true,\n  \"cache_ttl\": 3600,\n  \"escalation_threshold_hours\": 24,\n  \"auto_escalate_critical\": true,\n  \"max_ticket_title_length\": 200,\n  \"max_ticket_description_length\": 10000,\n  \"default_priority\": \"medium\",\n  \"log_level\": \"INFO\"\n}\n```\n\n## Ticket Processing\n\n### Single Ticket\n\n```python\nfrom helpdesk_ai.domain.models import Ticket, Category, Priority\nfrom helpdesk_ai.services.triage import TriageService\nfrom helpdesk_ai.cli import create_default_triage_service\n\ntriage_service = create_default_triage_service()\n\nticket = Ticket(\n    ticket_id=\"TKT-20240101-ABC12345\",\n    title=\"Payment issue\",\n    description=\"Unable to process payment\",\n    requester_email=\"user@example.com\",\n    category=Category.BILLING,\n    priority=Priority.HIGH,\n)\n\nresult = triage_service.triage(ticket)\n```\n\n### Batch Processing\n\n```python\ntickets = [ticket1, ticket2, ticket3]\nresults = triage_service.batch_triage(tickets)\n```\n\n## Storage Management\n\n### Memory Store\n\n```python\nfrom helpdesk_ai.store.memory_store import MemoryStore\n\nstore = MemoryStore()\nstore.save(ticket)\n```\n\n### File Store\n\n```python\nfrom helpdesk_ai.store.file_store import FileStore\n\nstore = FileStore(\"./data\")\nstore.save(ticket)\n```\n\n### Backup\n\nFile store backups:\n\n```bash\ntar -czf backup-$(date +%Y%m%d).tar.gz ./data/tickets/\n```\n\n### Restore\n\n```bash\ntar -xzf backup-20240101.tar.gz\n```\n\n## Monitoring\n\n### Check Service Health\n\n```python\nfrom helpdesk_ai.web.handlers import HealthHandler\n\nhandler = HealthHandler()\nresponse = handler.get()\n```\n\n### View Audit Logs\n\n```python\nfrom helpdesk_ai.services.audit import AuditService\n\naudit_service = AuditService()\nlogs = audit_service.get_recent_logs(limit=100)\nfor log in logs:\n    print(f\"{log.timestamp}: {log.action} on {log.ticket_id}\")\n```\n\n### Ticket Statistics\n\n```python\nfrom helpdesk_ai.store.memory_store import MemoryStore\n\nstore = MemoryStore()\ntickets = store.list_all()\n\nby_status = {}\nfor ticket in tickets:\n    status = ticket.status.value\n    by_status[status] = by_status.get(status, 0) + 1\n\nprint(by_status)\n```\n\n## Troubleshooting\n\n### Common Issues\n\n#### Parsing Errors\n\n**Symptom**: \"Error parsing input\"\n\n**Solution**: Check input format matches expected format (JSON, CSV, or text)\n\n#### Validation Errors\n\n**Symptom**: \"Validation errors\" with field names\n\n**Solution**: Ensure all required fields are present and valid:\n- ticket_id: Must match pattern\n- title: Required, max 200 chars\n- description: Required, non-empty\n- requester_email: Valid email format\n\n#### Storage Errors\n\n**Symptom**: \"StorageError\" exceptions\n\n**Solution**: \n- Check file permissions for file store\n- Ensure directory exists\n- Verify disk space\n\n#### Routing Issues\n\n**Symptom**: Tickets not routing correctly\n\n**Solution**:\n- Check rule conditions\n- Verify rule priority ordering\n- Review rule matching logic\n\n#### Scoring Issues\n\n**Symptom**: Unexpected scores\n\n**Solution**:\n- Check scorer weights\n- Verify normalization logic\n- Review component scores\n\n### Debug Mode\n\nEnable verbose logging:\n\n```python\nimport logging\nlogging.basicConfig(level=logging.DEBUG)\n```\n\n## Performance Tuning\n\n### Caching\n\nEnable caching for repeated operations:\n\n```python\nfrom helpdesk_ai.store.cache import MemoryCache\n\ncache = MemoryCache(default_ttl=3600)\n```\n\n### Batch Operations\n\nUse batch methods for multiple tickets:\n\n```python\nresults = triage_service.batch_triage(tickets)\n```\n\n### Storage Selection\n\n- Memory store: Fastest, no persistence\n- File store: Slower, persistent\n\nChoose based on requirements.\n\n## Maintenance\n\n### Cleanup Old Tickets\n\n```python\nfrom datetime import datetime, timedelta\n\ncutoff = datetime.now() - timedelta(days=90)\nold_tickets = [t for t in store.list_all() if t.created_at < cutoff]\nfor ticket in old_tickets:\n    store.delete(ticket.ticket_id)\n```\n\n### Clear Cache\n\n```python\ncache.clear()\n```\n\n### Archive Audit Logs\n\n```python\nold_logs = [l for l in audit_service._logs if l.timestamp < cutoff]\n# Export to external system\naudit_service.clear()\n```\n\n## Scaling Considerations\n\n### Horizontal Scaling\n\n- Stateless design allows multiple instances\n- Shared storage backend required\n- Consider distributed cache (Redis)\n\n### Vertical Scaling\n\n- Increase cache size\n- Optimize scoring algorithms\n- Use faster storage backend\n\n### Load Balancing\n\n- Route requests to multiple instances\n- Session affinity not required (stateless)\n- Health check endpoints available\n\n## Security\n\n### Input Validation\n\nAlways validate input:\n\n```python\nvalidator = TicketValidator()\nerrors = validator.validate(data)\nif errors:\n    raise ValidationError(\"Invalid input\")\n```\n\n### Access Control\n\nImplement authentication/authorization in web layer.\n\n### Data Protection\n\n- Encrypt sensitive data in metadata\n- Secure storage backend\n- Audit all operations\n\n## Disaster Recovery\n\n### Backup Strategy\n\n1. Regular file store backups\n2. Export audit logs\n3. Configuration backups\n\n### Recovery Procedures\n\n1. Restore from backup\n2. Verify data integrity\n3. Resume operations\n\n### Testing\n\nRegularly test backup/restore procedures.\n\n\n\n===== FILE: docs\\SECURITY.md =====\n# Security Documentation\n\n## Security Considerations\n\nThis document outlines security considerations for the Helpdesk AI service.\n\n## Input Validation\n\nAll input must be validated before processing:\n\n- Ticket data validated for format and constraints\n- Email addresses validated for proper format\n- Ticket IDs validated for pattern matching\n- Text fields checked for length limits\n\nUse validators for all user-provided data.\n\n## Data Sanitization\n\nText inputs are normalized:\n\n- Whitespace normalized\n- Line breaks standardized\n- Special characters handled appropriately\n\nEmail extraction uses regex patterns to prevent injection.\n\n## Storage Security\n\n### File Store\n\n- File permissions should restrict access\n- Path traversal prevented by validation\n- Filenames sanitized before use\n\n### Memory Store\n\n- In-memory data accessible to process\n- Consider encryption for sensitive data\n- Clear sensitive data when done\n\n## Authentication and Authorization\n\nThe current implementation does not include authentication. For production:\n\n- Implement authentication mechanism\n- Authorize operations by role\n- Track actor in audit logs\n- Validate permissions before operations\n\n## Audit Logging\n\nAll operations are logged:\n\n- Who performed action (actor)\n- What action was performed\n- When action occurred\n- What changes were made\n\nAudit logs should be:\n- Immutable (append-only)\n- Tamper-evident\n- Retained per retention policy\n- Access-controlled\n\n## Error Handling\n\nErrors should not expose:\n\n- Internal system details\n- File paths\n- Stack traces (in production)\n- Database schemas\n\nReturn generic error messages to users, log details internally.\n\n## Configuration Security\n\n### Environment Variables\n\n- Store secrets in environment variables\n- Don't commit secrets to version control\n- Rotate secrets regularly\n- Use secret management systems\n\n### Config Files\n\n- Restrict file permissions\n- Don't store secrets in config files\n- Validate config file contents\n- Use separate configs per environment\n\n## Cache Security\n\nCache considerations:\n\n- Cache keys should not be predictable\n- Sensitive data should not be cached\n- Implement cache expiration\n- Clear cache on security events\n\n## API Security\n\n### Input Validation\n\n- Validate all API inputs\n- Check data types and ranges\n- Sanitize text inputs\n- Reject malformed requests\n\n### Rate Limiting\n\nImplement rate limiting to prevent abuse:\n\n- Limit requests per IP\n- Limit requests per user\n- Implement backoff on failures\n\n### CORS\n\nConfigure CORS appropriately:\n\n- Restrict allowed origins\n- Limit allowed methods\n- Validate headers\n\n## Data Privacy\n\n### Personal Data\n\nEmail addresses are personal data:\n\n- Handle according to privacy policy\n- Allow deletion requests\n- Anonymize in logs if required\n- Encrypt at rest if needed\n\n### Retention\n\nImplement data retention policies:\n\n- Delete old tickets per policy\n- Archive audit logs\n- Clear cache regularly\n\n## Dependency Security\n\n- Keep dependencies updated\n- Scan for vulnerabilities\n- Use trusted sources\n- Review dependency licenses\n\n## Secure Development\n\n### Code Review\n\n- Review all code changes\n- Check for security issues\n- Validate input handling\n- Verify error handling\n\n### Testing\n\n- Test security controls\n- Test input validation\n- Test error handling\n- Test access controls\n\n## Incident Response\n\n### Detection\n\n- Monitor for anomalies\n- Alert on security events\n- Log security-relevant events\n- Track audit logs\n\n### Response\n\n- Document incidents\n- Contain impact\n- Investigate root cause\n- Implement fixes\n- Update procedures\n\n## Compliance\n\nConsider compliance requirements:\n\n- Data protection regulations\n- Industry standards\n- Internal policies\n- Audit requirements\n\n## Recommendations\n\nFor production deployment:\n\n1. Implement authentication/authorization\n2. Encrypt sensitive data\n3. Use HTTPS for all communications\n4. Implement rate limiting\n5. Regular security audits\n6. Dependency vulnerability scanning\n7. Secure configuration management\n8. Comprehensive logging\n9. Incident response plan\n10. Regular backups\n\n## Security Checklist\n\nBefore production:\n\n- [ ] Input validation implemented\n- [ ] Authentication/authorization added\n- [ ] Secrets management configured\n- [ ] Audit logging enabled\n- [ ] Error handling secure\n- [ ] Dependencies updated\n- [ ] Security testing completed\n- [ ] Incident response plan ready\n- [ ] Backup procedures tested\n- [ ] Monitoring configured\n\n\n\n===== FILE: src\\helpdesk_ai\\cli.py =====\n\"\"\"\nCommand-line interface for helpdesk service.\n\"\"\"\n\nimport sys\nimport json\nfrom pathlib import Path\nfrom typing import Optional\n\nfrom .domain.models import Ticket, Category, Priority\nfrom .ingest.parsers import JSONParser, TextParser, MultiFormatParser\nfrom .ingest.normalize import TicketNormalizer\nfrom .ingest.validators import TicketValidator\nfrom .store.memory_store import MemoryStore\nfrom .store.file_store import FileStore\nfrom .services.triage import TriageService\nfrom .services.routing import Router\nfrom .services.escalation import EscalationService\nfrom .domain.rules import RuleEngine, Rule\nfrom .domain.scoring import WeightedScorer, PriorityScorer, UrgencyScorer\nfrom .config import Config\n\n\ndef create_default_triage_service() -> TriageService:\n    \"\"\"Create a default triage service with standard configuration.\"\"\"\n    # Create scorers\n    priority_scorer = PriorityScorer()\n    urgency_scorer = UrgencyScorer()\n    \n    # Create weighted scorer\n    scorer = WeightedScorer(\n        scorers={\n            \"priority\": priority_scorer.score,\n            \"urgency\": urgency_scorer.score,\n        },\n        weights={\n            \"priority\": 0.6,\n            \"urgency\": 0.4,\n        },\n        normalize=True,\n    )\n    \n    # Create rule engine\n    rule_engine = RuleEngine()\n    \n    # Add some default rules\n    rule_engine.add_rule(Rule(\n        rule_id=\"critical_billing\",\n        name=\"Critical Billing Issues\",\n        priority=Priority.CRITICAL,\n        condition=lambda t: t.category == Category.BILLING and \"payment\" in t.description.lower(),\n        target_category=Category.BILLING,\n        target_assignee=\"billing-team\",\n    ))\n    \n    rule_engine.add_rule(Rule(\n        rule_id=\"account_lockout\",\n        name=\"Account Lockout\",\n        priority=Priority.HIGH,\n        condition=lambda t: \"lock\" in t.title.lower() or \"lockout\" in t.description.lower(),\n        target_category=Category.ACCOUNT,\n        target_assignee=\"account-team\",\n    ))\n    \n    # Create router\n    router = Router(rule_engine)\n    \n    # Create triage service\n    return TriageService(scorer=scorer, router=router)\n\n\ndef process_ticket_file(input_file: str, output_file: Optional[str] = None) -> None:\n    \"\"\"Process a ticket file and output results.\"\"\"\n    # Read input\n    with open(input_file, \"r\") as f:\n        content = f.read()\n    \n    # Parse\n    parser = MultiFormatParser()\n    try:\n        data = parser.parse(content)\n    except Exception as e:\n        print(f\"Error parsing input: {e}\", file=sys.stderr)\n        sys.exit(1)\n    \n    # Validate\n    validator = TicketValidator()\n    errors = validator.validate(data)\n    if errors:\n        print(\"Validation errors:\", file=sys.stderr)\n        for error in errors:\n            print(f\"  - {error.field}: {error.message}\", file=sys.stderr)\n        sys.exit(1)\n    \n    # Normalize\n    normalizer = TicketNormalizer()\n    try:\n        ticket = normalizer.normalize(data)\n    except Exception as e:\n        print(f\"Error normalizing ticket: {e}\", file=sys.stderr)\n        sys.exit(1)\n    \n    # Triage\n    triage_service = create_default_triage_service()\n    result = triage_service.triage(ticket)\n    \n    # Output\n    output_data = {\n        \"ticket\": ticket.to_dict(),\n        \"routing\": {\n            \"assigned_to\": result.assigned_to,\n            \"priority\": result.priority.value,\n            \"category\": result.category.value,\n            \"rule_matched\": result.rule_matched,\n            \"confidence\": result.confidence,\n        },\n    }\n    \n    if output_file:\n        with open(output_file, \"w\") as f:\n            json.dump(output_data, f, indent=2)\n    else:\n        print(json.dumps(output_data, indent=2))\n\n\ndef main() -> None:\n    \"\"\"Main CLI entry point.\"\"\"\n    if len(sys.argv) < 2:\n        print(\"Usage: helpdesk-ai <input_file> [output_file]\", file=sys.stderr)\n        sys.exit(1)\n    \n    input_file = sys.argv[1]\n    output_file = sys.argv[2] if len(sys.argv) > 2 else None\n    \n    if not Path(input_file).exists():\n        print(f\"Input file not found: {input_file}\", file=sys.stderr)\n        sys.exit(1)\n    \n    process_ticket_file(input_file, output_file)\n\n\nif __name__ == \"__main__\":\n    main()\n\n\n\n===== FILE: src\\helpdesk_ai\\config.py =====\n\"\"\"\nConfiguration management for helpdesk service.\n\"\"\"\n\nimport os\nimport json\nfrom pathlib import Path\nfrom typing import Dict, Any, Optional\n\n\nclass Config:\n    \"\"\"\n    Configuration manager with support for environment variables and config files.\n    \n    BUG: Config precedence inconsistency - environment variables override file config\n    in some methods but not others. The load_from_file method doesn't respect\n    existing env vars, and get() method checks env first but set() only updates\n    internal dict, not env vars.\n    \"\"\"\n    \n    def __init__(self, config_file: Optional[str] = None):\n        \"\"\"Initialize config manager.\"\"\"\n        self.config_file = config_file\n        self._config: Dict[str, Any] = {}\n        self._load_defaults()\n        \n        if config_file and Path(config_file).exists():\n            self.load_from_file(config_file)\n        \n        # BUG: Environment variables should override file config, but this\n        # only happens in get(), not during initialization\n        self._load_from_env()\n    \n    def _load_defaults(self) -> None:\n        \"\"\"Load default configuration values.\"\"\"\n        self._config = {\n            \"store_type\": \"memory\",\n            \"store_path\": \"./data\",\n            \"cache_enabled\": True,\n            \"cache_ttl\": 3600,\n            \"escalation_threshold_hours\": 24,\n            \"auto_escalate_critical\": True,\n            \"max_ticket_title_length\": 200,\n            \"max_ticket_description_length\": 10000,\n            \"default_priority\": \"medium\",\n            \"log_level\": \"INFO\",\n        }\n    \n    def load_from_file(self, config_file: str) -> None:\n        \"\"\"Load configuration from JSON file.\"\"\"\n        path = Path(config_file)\n        if not path.exists():\n            return\n        \n        try:\n            with open(path, \"r\") as f:\n                file_config = json.load(f)\n            \n            # BUG: This overwrites everything, including values that might\n            # have been set via environment variables\n            self._config.update(file_config)\n        except Exception:\n            pass\n    \n    def _load_from_env(self) -> None:\n        \"\"\"Load configuration from environment variables.\"\"\"\n        env_mapping = {\n            \"HELPDESK_STORE_TYPE\": \"store_type\",\n            \"HELPDESK_STORE_PATH\": \"store_path\",\n            \"HELPDESK_CACHE_ENABLED\": \"cache_enabled\",\n            \"HELPDESK_CACHE_TTL\": \"cache_ttl\",\n            \"HELPDESK_ESCALATION_THRESHOLD\": \"escalation_threshold_hours\",\n            \"HELPDESK_LOG_LEVEL\": \"log_level\",\n        }\n        \n        for env_var, config_key in env_mapping.items():\n            value = os.environ.get(env_var)\n            if value is not None:\n                # BUG: Type conversion is inconsistent - some values are strings,\n                # some are converted, but not all env vars are handled\n                if config_key in [\"cache_enabled\", \"auto_escalate_critical\"]:\n                    self._config[config_key] = value.lower() in [\"true\", \"1\", \"yes\"]\n                elif config_key in [\"cache_ttl\", \"escalation_threshold_hours\", \"max_ticket_title_length\"]:\n                    try:\n                        self._config[config_key] = int(value)\n                    except ValueError:\n                        pass\n                else:\n                    self._config[config_key] = value\n    \n    def get(self, key: str, default: Any = None) -> Any:\n        \"\"\"\n        Get configuration value.\n        \n        BUG: Checks env var first, but if env var exists, it returns string\n        even if the config file had a different type. Type consistency is broken.\n        \"\"\"\n        # BUG: Environment variable check happens here, but env vars might\n        # have different types than config file values\n        env_key = f\"HELPDESK_{key.upper()}\"\n        env_value = os.environ.get(env_key)\n        if env_value is not None:\n            return env_value\n        \n        return self._config.get(key, default)\n    \n    def set(self, key: str, value: Any) -> None:\n        \"\"\"Set configuration value.\"\"\"\n        # BUG: This only updates internal dict, doesn't update env vars\n        # So subsequent get() calls might return env var instead\n        self._config[key] = value\n    \n    def save_to_file(self, config_file: Optional[str] = None) -> None:\n        \"\"\"Save configuration to file.\"\"\"\n        file_path = config_file or self.config_file\n        if not file_path:\n            return\n        \n        path = Path(file_path)\n        path.parent.mkdir(parents=True, exist_ok=True)\n        \n        with open(path, \"w\") as f:\n            json.dump(self._config, f, indent=2)\n    \n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert config to dictionary.\"\"\"\n        return self._config.copy()\n\n\n\n===== FILE: src\\helpdesk_ai\\__init__.py =====\n\"\"\"\nHelpdesk AI Triage Service\n\nA service for triaging and routing helpdesk tickets using rule-based\nscoring and priority assignment.\n\"\"\"\n\n__version__ = \"0.1.0\"\n\n\n\n===== FILE: src\\helpdesk_ai\\domain\\models.py =====\n\"\"\"\nDomain models for helpdesk tickets and related entities.\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Optional, Dict, Any, List\n\n\nclass TicketStatus(Enum):\n    \"\"\"Ticket status enumeration.\"\"\"\n    NEW = \"new\"\n    TRIAGED = \"triaged\"\n    ASSIGNED = \"assigned\"\n    IN_PROGRESS = \"in_progress\"\n    RESOLVED = \"resolved\"\n    CLOSED = \"closed\"\n    ESCALATED = \"escalated\"\n\n\nclass Priority(Enum):\n    \"\"\"Priority levels for tickets.\"\"\"\n    CRITICAL = \"critical\"\n    HIGH = \"high\"\n    MEDIUM = \"medium\"\n    LOW = \"low\"\n\n\nclass Category(Enum):\n    \"\"\"Ticket category enumeration.\"\"\"\n    TECHNICAL = \"technical\"\n    BILLING = \"billing\"\n    ACCOUNT = \"account\"\n    FEATURE = \"feature\"\n    BUG = \"bug\"\n    GENERAL = \"general\"\n\n\n@dataclass\nclass Ticket:\n    \"\"\"Represents a helpdesk ticket.\"\"\"\n    \n    ticket_id: str\n    title: str\n    description: str\n    requester_email: str\n    category: Category\n    priority: Priority = Priority.MEDIUM\n    status: TicketStatus = TicketStatus.NEW\n    created_at: datetime = field(default_factory=datetime.now)\n    updated_at: datetime = field(default_factory=datetime.now)\n    assigned_to: Optional[str] = None\n    tags: List[str] = field(default_factory=list)\n    metadata: Dict[str, Any] = field(default_factory=dict)\n    score: Optional[float] = None\n    \n    def update(self, **kwargs) -> None:\n        \"\"\"Update ticket fields and set updated_at timestamp.\"\"\"\n        for key, value in kwargs.items():\n            if hasattr(self, key):\n                setattr(self, key, value)\n        self.updated_at = datetime.now()\n    \n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert ticket to dictionary representation.\"\"\"\n        return {\n            \"ticket_id\": self.ticket_id,\n            \"title\": self.title,\n            \"description\": self.description,\n            \"requester_email\": self.requester_email,\n            \"category\": self.category.value,\n            \"priority\": self.priority.value,\n            \"status\": self.status.value,\n            \"created_at\": self.created_at.isoformat(),\n            \"updated_at\": self.updated_at.isoformat(),\n            \"assigned_to\": self.assigned_to,\n            \"tags\": self.tags,\n            \"metadata\": self.metadata,\n            \"score\": self.score,\n        }\n    \n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> \"Ticket\":\n        \"\"\"Create ticket from dictionary representation.\"\"\"\n        data = data.copy()\n        data[\"category\"] = Category(data[\"category\"])\n        data[\"priority\"] = Priority(data[\"priority\"])\n        data[\"status\"] = TicketStatus(data[\"status\"])\n        data[\"created_at\"] = datetime.fromisoformat(data[\"created_at\"])\n        data[\"updated_at\"] = datetime.fromisoformat(data[\"updated_at\"])\n        return cls(**data)\n\n\n@dataclass\nclass TicketUpdate:\n    \"\"\"Represents an update to a ticket.\"\"\"\n    \n    ticket_id: str\n    field: str\n    old_value: Any\n    new_value: Any\n    updated_by: str\n    timestamp: datetime = field(default_factory=datetime.now)\n    reason: Optional[str] = None\n\n\n\n===== FILE: src\\helpdesk_ai\\domain\\rules.py =====\n\"\"\"\nRule engine for matching tickets against routing rules.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import List, Optional, Callable, Dict, Any\nfrom .models import Ticket, Priority, Category\n\n\n@dataclass\nclass RuleMatch:\n    \"\"\"Represents a match between a ticket and a rule.\"\"\"\n    \n    rule_id: str\n    rule_name: str\n    matched: bool\n    confidence: float\n    metadata: Dict[str, Any] = None\n\n\n@dataclass\nclass Rule:\n    \"\"\"A routing rule that can match tickets.\"\"\"\n    \n    rule_id: str\n    name: str\n    priority: Priority\n    condition: Callable[[Ticket], bool]\n    target_category: Optional[Category] = None\n    target_assignee: Optional[str] = None\n    metadata: Dict[str, Any] = None\n    \n    def matches(self, ticket: Ticket) -> RuleMatch:\n        \"\"\"Check if this rule matches the given ticket.\"\"\"\n        try:\n            matched = self.condition(ticket)\n            confidence = 1.0 if matched else 0.0\n            return RuleMatch(\n                rule_id=self.rule_id,\n                rule_name=self.name,\n                matched=matched,\n                confidence=confidence,\n                metadata=self.metadata or {},\n            )\n        except Exception as e:\n            return RuleMatch(\n                rule_id=self.rule_id,\n                rule_name=self.name,\n                matched=False,\n                confidence=0.0,\n                metadata={\"error\": str(e)},\n            )\n\n\nclass RuleEngine:\n    \"\"\"Engine for evaluating rules against tickets.\"\"\"\n    \n    def __init__(self, rules: Optional[List[Rule]] = None):\n        \"\"\"Initialize rule engine with optional initial rules.\"\"\"\n        self.rules: List[Rule] = rules or []\n    \n    def add_rule(self, rule: Rule) -> None:\n        \"\"\"Add a rule to the engine.\"\"\"\n        self.rules.append(rule)\n    \n    def remove_rule(self, rule_id: str) -> bool:\n        \"\"\"Remove a rule by ID. Returns True if removed.\"\"\"\n        initial_len = len(self.rules)\n        self.rules = [r for r in self.rules if r.rule_id != rule_id]\n        return len(self.rules) < initial_len\n    \n    def evaluate(self, ticket: Ticket) -> List[RuleMatch]:\n        \"\"\"Evaluate all rules against a ticket.\"\"\"\n        matches = []\n        for rule in self.rules:\n            match = rule.matches(ticket)\n            matches.append(match)\n        return matches\n    \n    def get_matching_rules(self, ticket: Ticket) -> List[Rule]:\n        \"\"\"Get all rules that match the ticket.\"\"\"\n        matches = self.evaluate(ticket)\n        matching_rules = []\n        for match in matches:\n            if match.matched:\n                rule = next(r for r in self.rules if r.rule_id == match.rule_id)\n                matching_rules.append(rule)\n        return matching_rules\n    \n    def get_highest_priority_match(self, ticket: Ticket) -> Optional[Rule]:\n        \"\"\"\n        Get the highest priority rule that matches the ticket.\n        \n        BUG: Priority ordering is inverted - CRITICAL is treated as lowest priority.\n        Should use priority.value ordering or explicit priority enum comparison.\n        \"\"\"\n        matches = self.get_matching_rules(ticket)\n        if not matches:\n            return None\n        \n        # BUG: This comparison is inverted\n        # CRITICAL should be highest, but this treats it as lowest\n        priority_order = {\n            Priority.CRITICAL: 1,\n            Priority.HIGH: 2,\n            Priority.MEDIUM: 3,\n            Priority.LOW: 4,\n        }\n        \n        # Sort by priority value (lower number = higher priority)\n        # But the mapping above is correct, so the bug is in the comparison\n        matches.sort(key=lambda r: priority_order.get(r.priority, 99))\n        \n        # Actually, wait - the bug is that we're returning the LAST one after sorting\n        # ascending, which means LOW priority wins. Should return FIRST.\n        return matches[-1] if matches else None\n\n\n\n===== FILE: src\\helpdesk_ai\\domain\\scoring.py =====\n\"\"\"\nScoring system for ticket prioritization and routing.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Dict, List, Optional, Callable\nfrom .models import Ticket, Priority\n\n\n@dataclass\nclass Score:\n    \"\"\"Represents a score with components.\"\"\"\n    \n    total: float\n    components: Dict[str, float]\n    normalized: Optional[float] = None\n    \n    def __repr__(self) -> str:\n        return f\"Score(total={self.total:.2f}, normalized={self.normalized:.2f if self.normalized else None})\"\n\n\nclass Scorer:\n    \"\"\"Base scorer interface.\"\"\"\n    \n    def score(self, ticket: Ticket) -> Score:\n        \"\"\"Calculate score for a ticket.\"\"\"\n        raise NotImplementedError\n\n\nclass WeightedScorer(Scorer):\n    \"\"\"\n    Scorer that combines multiple scoring functions with weights.\n    \n    BUG: Normalization can divide by zero when sum of weights is zero.\n    Also, if weights dict is empty, normalization fails silently.\n    \"\"\"\n    \n    def __init__(\n        self,\n        scorers: Dict[str, Callable[[Ticket], float]],\n        weights: Optional[Dict[str, float]] = None,\n        normalize: bool = True,\n    ):\n        \"\"\"\n        Initialize weighted scorer.\n        \n        Args:\n            scorers: Dictionary mapping scorer names to scoring functions\n            weights: Optional weights for each scorer (defaults to equal weights)\n            normalize: Whether to normalize the final score to [0, 1]\n        \"\"\"\n        self.scorers = scorers\n        self.weights = weights or {name: 1.0 for name in scorers.keys()}\n        self.normalize = normalize\n    \n    def score(self, ticket: Ticket) -> Score:\n        \"\"\"Calculate weighted score for a ticket.\"\"\"\n        components = {}\n        weighted_sum = 0.0\n        \n        for name, scorer_func in self.scorers.items():\n            component_score = scorer_func(ticket)\n            weight = self.weights.get(name, 1.0)\n            components[name] = component_score\n            weighted_sum += component_score * weight\n        \n        # BUG: If sum of weights is zero, normalization divides by zero\n        # Also, if weights dict is empty, this will fail\n        if self.normalize:\n            weight_sum = sum(self.weights.values())\n            # BUG: No check for weight_sum == 0\n            normalized = weighted_sum / weight_sum if weight_sum > 0 else 0.0\n        else:\n            normalized = None\n        \n        return Score(\n            total=weighted_sum,\n            components=components,\n            normalized=normalized,\n        )\n\n\nclass PriorityScorer(Scorer):\n    \"\"\"Scorer based on ticket priority.\"\"\"\n    \n    PRIORITY_WEIGHTS = {\n        Priority.CRITICAL: 10.0,\n        Priority.HIGH: 7.0,\n        Priority.MEDIUM: 4.0,\n        Priority.LOW: 1.0,\n    }\n    \n    def score(self, ticket: Ticket) -> Score:\n        \"\"\"Score ticket based on priority.\"\"\"\n        priority_score = self.PRIORITY_WEIGHTS.get(ticket.priority, 0.0)\n        return Score(\n            total=priority_score,\n            components={\"priority\": priority_score},\n            normalized=priority_score / 10.0,\n        )\n\n\nclass UrgencyScorer(Scorer):\n    \"\"\"Scorer based on ticket urgency indicators.\"\"\"\n    \n    def __init__(self, urgency_keywords: Optional[List[str]] = None):\n        \"\"\"Initialize with optional urgency keywords.\"\"\"\n        self.urgency_keywords = urgency_keywords or [\n            \"urgent\", \"critical\", \"down\", \"broken\", \"emergency\",\n            \"outage\", \"cannot\", \"unable\", \"failed\", \"error\",\n        ]\n    \n    def score(self, ticket: Ticket) -> Score:\n        \"\"\"Score ticket based on urgency keywords in title/description.\"\"\"\n        text = (ticket.title + \" \" + ticket.description).lower()\n        matches = sum(1 for keyword in self.urgency_keywords if keyword in text)\n        urgency_score = min(matches * 2.0, 10.0)  # Cap at 10.0\n        \n        return Score(\n            total=urgency_score,\n            components={\"urgency\": urgency_score},\n            normalized=urgency_score / 10.0,\n        )\n\n\nclass CompositeScorer(Scorer):\n    \"\"\"Composite scorer combining multiple scorers.\"\"\"\n    \n    def __init__(self, scorers: List[Scorer], weights: Optional[List[float]] = None):\n        \"\"\"Initialize composite scorer.\"\"\"\n        self.scorers = scorers\n        self.weights = weights or [1.0] * len(scorers)\n        if len(self.weights) != len(self.scorers):\n            self.weights = [1.0] * len(self.scorers)\n    \n    def score(self, ticket: Ticket) -> Score:\n        \"\"\"Calculate composite score.\"\"\"\n        all_components = {}\n        weighted_sum = 0.0\n        \n        for i, scorer in enumerate(self.scorers):\n            score_result = scorer.score(ticket)\n            weight = self.weights[i] if i < len(self.weights) else 1.0\n            \n            for comp_name, comp_value in score_result.components.items():\n                all_components[f\"{scorer.__class__.__name__}.{comp_name}\"] = comp_value\n            \n            weighted_sum += score_result.total * weight\n        \n        total_weight = sum(self.weights)\n        normalized = weighted_sum / total_weight if total_weight > 0 else 0.0\n        \n        return Score(\n            total=weighted_sum,\n            components=all_components,\n            normalized=normalized,\n        )\n\n\n\n===== FILE: src\\helpdesk_ai\\domain\\__init__.py =====\n\"\"\"Domain models and business logic for helpdesk triage.\"\"\"\n\nfrom .models import Ticket, TicketStatus, Priority, Category\nfrom .rules import Rule, RuleEngine, RuleMatch\nfrom .scoring import Score, Scorer, WeightedScorer\n\n__all__ = [\n    \"Ticket\",\n    \"TicketStatus\",\n    \"Priority\",\n    \"Category\",\n    \"Rule\",\n    \"RuleEngine\",\n    \"RuleMatch\",\n    \"Score\",\n    \"Scorer\",\n    \"WeightedScorer\",\n]\n\n\n\n===== FILE: src\\helpdesk_ai\\ingest\\normalize.py =====\n\"\"\"\nNormalizers for converting parsed data into domain models.\n\"\"\"\n\nfrom typing import Dict, Any, Optional\nfrom ..domain.models import Ticket, Category, Priority, TicketStatus\nfrom ..utils.text import normalize_text, extract_email\n\n\nclass Normalizer:\n    \"\"\"Base normalizer interface.\"\"\"\n    \n    def normalize(self, data: Dict[str, Any]) -> Any:\n        \"\"\"Normalize parsed data into domain model.\"\"\"\n        raise NotImplementedError\n\n\nclass TicketNormalizer(Normalizer):\n    \"\"\"Normalizer for ticket data.\"\"\"\n    \n    CATEGORY_MAP = {\n        \"tech\": Category.TECHNICAL,\n        \"technical\": Category.TECHNICAL,\n        \"billing\": Category.BILLING,\n        \"bill\": Category.BILLING,\n        \"account\": Category.ACCOUNT,\n        \"feature\": Category.FEATURE,\n        \"bug\": Category.BUG,\n        \"error\": Category.BUG,\n        \"general\": Category.GENERAL,\n    }\n    \n    PRIORITY_MAP = {\n        \"critical\": Priority.CRITICAL,\n        \"high\": Priority.HIGH,\n        \"medium\": Priority.MEDIUM,\n        \"low\": Priority.LOW,\n        \"urgent\": Priority.HIGH,\n        \"normal\": Priority.MEDIUM,\n    }\n    \n    def normalize(self, data: Dict[str, Any]) -> Ticket:\n        \"\"\"Normalize parsed data into Ticket object.\"\"\"\n        # Extract and normalize fields\n        ticket_id = data.get(\"ticket_id\") or data.get(\"id\") or data.get(\"ticket\")\n        if not ticket_id:\n            raise ValueError(\"ticket_id is required\")\n        \n        title = normalize_text(data.get(\"title\") or data.get(\"subject\") or \"\")\n        if not title:\n            raise ValueError(\"title is required\")\n        \n        description = normalize_text(data.get(\"description\") or data.get(\"body\") or \"\")\n        if not description:\n            raise ValueError(\"description is required\")\n        \n        # Extract email from various fields\n        email = data.get(\"requester_email\") or data.get(\"email\") or data.get(\"user_email\")\n        if not email:\n            # Try to extract from description or other fields\n            email = extract_email(data.get(\"description\", \"\") + \" \" + data.get(\"contact\", \"\"))\n        if not email:\n            raise ValueError(\"requester_email is required\")\n        \n        # Normalize category\n        category_str = (data.get(\"category\") or data.get(\"type\") or \"general\").lower()\n        category = self.CATEGORY_MAP.get(category_str, Category.GENERAL)\n        \n        # Normalize priority\n        priority_str = (data.get(\"priority\") or \"medium\").lower()\n        priority = self.PRIORITY_MAP.get(priority_str, Priority.MEDIUM)\n        \n        # Normalize status\n        status_str = (data.get(\"status\") or \"new\").lower()\n        try:\n            status = TicketStatus(status_str)\n        except ValueError:\n            status = TicketStatus.NEW\n        \n        # Extract optional fields\n        assigned_to = data.get(\"assigned_to\") or data.get(\"assignee\")\n        tags = data.get(\"tags\", [])\n        if isinstance(tags, str):\n            tags = [t.strip() for t in tags.split(\",\")]\n        \n        metadata = {k: v for k, v in data.items() \n                   if k not in [\"ticket_id\", \"id\", \"ticket\", \"title\", \"subject\",\n                               \"description\", \"body\", \"requester_email\", \"email\",\n                               \"category\", \"type\", \"priority\", \"status\",\n                               \"assigned_to\", \"assignee\", \"tags\"]}\n        \n        return Ticket(\n            ticket_id=str(ticket_id),\n            title=title,\n            description=description,\n            requester_email=email,\n            category=category,\n            priority=priority,\n            status=status,\n            assigned_to=assigned_to,\n            tags=tags,\n            metadata=metadata,\n        )\n\n\n\n===== FILE: src\\helpdesk_ai\\ingest\\parsers.py =====\n\"\"\"\nParsers for converting raw input data into structured ticket data.\n\"\"\"\n\nimport json\nimport csv\nfrom io import StringIO\nfrom typing import Dict, Any, List, Optional\nfrom ..domain.models import Ticket, Category, Priority, TicketStatus\n\n\nclass Parser:\n    \"\"\"Base parser interface.\"\"\"\n    \n    def parse(self, data: str) -> Dict[str, Any]:\n        \"\"\"Parse input data into a dictionary.\"\"\"\n        raise NotImplementedError\n\n\nclass JSONParser(Parser):\n    \"\"\"Parser for JSON-formatted ticket data.\"\"\"\n    \n    def parse(self, data: str) -> Dict[str, Any]:\n        \"\"\"Parse JSON data into ticket dictionary.\"\"\"\n        try:\n            parsed = json.loads(data)\n            if not isinstance(parsed, dict):\n                raise ValueError(\"JSON must be an object\")\n            return parsed\n        except json.JSONDecodeError as e:\n            raise ValueError(f\"Invalid JSON: {e}\")\n\n\nclass TextParser(Parser):\n    \"\"\"Parser for plain text ticket data.\"\"\"\n    \n    def __init__(self, delimiter: str = \"\\n\"):\n        \"\"\"Initialize text parser with delimiter.\"\"\"\n        self.delimiter = delimiter\n    \n    def parse(self, data: str) -> Dict[str, Any]:\n        \"\"\"Parse text data into ticket dictionary.\"\"\"\n        lines = data.split(self.delimiter)\n        result = {}\n        \n        for line in lines:\n            line = line.strip()\n            if not line or \":\" not in line:\n                continue\n            \n            key, value = line.split(\":\", 1)\n            key = key.strip().lower().replace(\" \", \"_\")\n            value = value.strip()\n            \n            if key == \"description\":\n                result.setdefault(\"description\", \"\")\n                result[\"description\"] += value + \"\\n\"\n            else:\n                result[key] = value\n        \n        if \"description\" in result:\n            result[\"description\"] = result[\"description\"].rstrip()\n        \n        return result\n\n\nclass CSVParser(Parser):\n    \"\"\"Parser for CSV-formatted ticket data.\"\"\"\n    \n    def __init__(self, has_header: bool = True):\n        \"\"\"Initialize CSV parser.\"\"\"\n        self.has_header = has_header\n    \n    def parse(self, data: str) -> Dict[str, Any]:\n        \"\"\"Parse CSV data into ticket dictionary.\"\"\"\n        reader = csv.reader(StringIO(data))\n        rows = list(reader)\n        \n        if not rows:\n            raise ValueError(\"CSV data is empty\")\n        \n        if self.has_header:\n            headers = [h.strip().lower().replace(\" \", \"_\") for h in rows[0]]\n            if len(rows) < 2:\n                raise ValueError(\"CSV has header but no data rows\")\n            values = rows[1]\n        else:\n            headers = [f\"field_{i}\" for i in range(len(rows[0]))]\n            values = rows[0]\n        \n        if len(headers) != len(values):\n            raise ValueError(\"Header and value count mismatch\")\n        \n        return dict(zip(headers, values))\n\n\nclass MultiFormatParser:\n    \"\"\"Parser that tries multiple formats.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize multi-format parser.\"\"\"\n        self.parsers = [\n            JSONParser(),\n            CSVParser(),\n            TextParser(),\n        ]\n    \n    def parse(self, data: str) -> Dict[str, Any]:\n        \"\"\"Try parsing with each parser until one succeeds.\"\"\"\n        errors = []\n        for parser in self.parsers:\n            try:\n                return parser.parse(data)\n            except Exception as e:\n                errors.append(f\"{parser.__class__.__name__}: {str(e)}\")\n        \n        raise ValueError(f\"Failed to parse with any parser: {'; '.join(errors)}\")\n\n\n\n===== FILE: src\\helpdesk_ai\\ingest\\validators.py =====\n\"\"\"\nValidators for ensuring data quality and completeness.\n\"\"\"\n\nfrom typing import Dict, Any, List, Optional\nimport re\n\n\nclass ValidationError(Exception):\n    \"\"\"Raised when validation fails.\"\"\"\n    \n    def __init__(self, message: str, field: Optional[str] = None):\n        \"\"\"Initialize validation error.\"\"\"\n        super().__init__(message)\n        self.field = field\n        self.message = message\n\n\nclass Validator:\n    \"\"\"Base validator interface.\"\"\"\n    \n    def validate(self, data: Dict[str, Any]) -> List[ValidationError]:\n        \"\"\"Validate data and return list of errors.\"\"\"\n        raise NotImplementedError\n\n\nclass TicketValidator(Validator):\n    \"\"\"Validator for ticket data.\"\"\"\n    \n    EMAIL_PATTERN = re.compile(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$')\n    TICKET_ID_PATTERN = re.compile(r'^[A-Z0-9-]+$')\n    \n    def validate(self, data: Dict[str, Any]) -> List[ValidationError]:\n        \"\"\"\n        Validate ticket data.\n        \n        BUG: Missing validation for 'description' field in one code path.\n        When data comes from certain parsers, description validation is skipped.\n        \"\"\"\n        errors = []\n        \n        # Validate ticket_id\n        ticket_id = data.get(\"ticket_id\") or data.get(\"id\") or data.get(\"ticket\")\n        if not ticket_id:\n            errors.append(ValidationError(\"ticket_id is required\", \"ticket_id\"))\n        elif not isinstance(ticket_id, str):\n            errors.append(ValidationError(\"ticket_id must be a string\", \"ticket_id\"))\n        elif not self.TICKET_ID_PATTERN.match(ticket_id):\n            errors.append(ValidationError(\"ticket_id format is invalid\", \"ticket_id\"))\n        \n        # Validate title\n        title = data.get(\"title\") or data.get(\"subject\")\n        if not title:\n            errors.append(ValidationError(\"title is required\", \"title\"))\n        elif not isinstance(title, str):\n            errors.append(ValidationError(\"title must be a string\", \"title\"))\n        elif len(title.strip()) == 0:\n            errors.append(ValidationError(\"title cannot be empty\", \"title\"))\n        elif len(title) > 200:\n            errors.append(ValidationError(\"title exceeds maximum length of 200\", \"title\"))\n        \n        # BUG: Description validation is missing when data comes from certain sources\n        # Specifically, if data has \"body\" but not \"description\", validation is skipped\n        description = data.get(\"description\")\n        if not description:\n            # Check alternative field names\n            description = data.get(\"body\")\n            if description:\n                # BUG: We found \"body\" but don't validate it here\n                # Should validate description even if it comes from \"body\" field\n                pass\n            else:\n                errors.append(ValidationError(\"description is required\", \"description\"))\n        elif not isinstance(description, str):\n            errors.append(ValidationError(\"description must be a string\", \"description\"))\n        elif len(description.strip()) == 0:\n            errors.append(ValidationError(\"description cannot be empty\", \"description\"))\n        \n        # Validate email\n        email = data.get(\"requester_email\") or data.get(\"email\") or data.get(\"user_email\")\n        if not email:\n            errors.append(ValidationError(\"requester_email is required\", \"requester_email\"))\n        elif not isinstance(email, str):\n            errors.append(ValidationError(\"requester_email must be a string\", \"requester_email\"))\n        elif not self.EMAIL_PATTERN.match(email):\n            errors.append(ValidationError(\"requester_email format is invalid\", \"requester_email\"))\n        \n        # Validate category if present\n        category = data.get(\"category\") or data.get(\"type\")\n        if category and not isinstance(category, str):\n            errors.append(ValidationError(\"category must be a string\", \"category\"))\n        \n        # Validate priority if present\n        priority = data.get(\"priority\")\n        if priority and not isinstance(priority, str):\n            errors.append(ValidationError(\"priority must be a string\", \"priority\"))\n        \n        return errors\n    \n    def validate_partial(self, data: Dict[str, Any]) -> List[ValidationError]:\n        \"\"\"\n        Validate partial ticket data (for updates).\n        \n        BUG: This method doesn't validate description at all, even when provided.\n        \"\"\"\n        errors = []\n        \n        # Only validate fields that are present\n        if \"ticket_id\" in data:\n            ticket_id = data[\"ticket_id\"]\n            if not isinstance(ticket_id, str):\n                errors.append(ValidationError(\"ticket_id must be a string\", \"ticket_id\"))\n            elif not self.TICKET_ID_PATTERN.match(ticket_id):\n                errors.append(ValidationError(\"ticket_id format is invalid\", \"ticket_id\"))\n        \n        if \"title\" in data:\n            title = data[\"title\"]\n            if not isinstance(title, str):\n                errors.append(ValidationError(\"title must be a string\", \"title\"))\n            elif len(title.strip()) == 0:\n                errors.append(ValidationError(\"title cannot be empty\", \"title\"))\n        \n        # BUG: Description validation completely missing in partial validation\n        # Should validate description if it's present in the update\n        \n        if \"requester_email\" in data:\n            email = data[\"requester_email\"]\n            if not isinstance(email, str):\n                errors.append(ValidationError(\"requester_email must be a string\", \"requester_email\"))\n            elif not self.EMAIL_PATTERN.match(email):\n                errors.append(ValidationError(\"requester_email format is invalid\", \"requester_email\"))\n        \n        return errors\n\n\n\n===== FILE: src\\helpdesk_ai\\ingest\\__init__.py =====\n\"\"\"Data ingestion and normalization modules.\"\"\"\n\nfrom .parsers import Parser, JSONParser, TextParser, CSVParser\nfrom .normalize import Normalizer, TicketNormalizer\nfrom .validators import Validator, TicketValidator, ValidationError\n\n__all__ = [\n    \"Parser\",\n    \"JSONParser\",\n    \"TextParser\",\n    \"CSVParser\",\n    \"Normalizer\",\n    \"TicketNormalizer\",\n    \"Validator\",\n    \"TicketValidator\",\n    \"ValidationError\",\n]\n\n\n\n===== FILE: src\\helpdesk_ai\\services\\audit.py =====\n\"\"\"\nAudit service for tracking ticket changes and operations.\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom typing import List, Optional, Dict, Any\nfrom ..domain.models import Ticket\n\n\n@dataclass\nclass AuditLog:\n    \"\"\"Represents an audit log entry.\"\"\"\n    \n    log_id: str\n    ticket_id: str\n    action: str\n    actor: str\n    timestamp: datetime = field(default_factory=datetime.now)\n    changes: Dict[str, Any] = field(default_factory=dict)\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\n\nclass AuditService:\n    \"\"\"Service for managing audit logs.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize audit service.\"\"\"\n        self._logs: List[AuditLog] = []\n    \n    def log(\n        self,\n        ticket_id: str,\n        action: str,\n        actor: str,\n        changes: Optional[Dict[str, Any]] = None,\n        metadata: Optional[Dict[str, Any]] = None,\n    ) -> AuditLog:\n        \"\"\"Create an audit log entry.\"\"\"\n        log_id = f\"audit_{len(self._logs) + 1}_{datetime.now().timestamp()}\"\n        log = AuditLog(\n            log_id=log_id,\n            ticket_id=ticket_id,\n            action=action,\n            actor=actor,\n            changes=changes or {},\n            metadata=metadata or {},\n        )\n        self._logs.append(log)\n        return log\n    \n    def get_logs_for_ticket(self, ticket_id: str) -> List[AuditLog]:\n        \"\"\"Get all audit logs for a ticket.\"\"\"\n        return [log for log in self._logs if log.ticket_id == ticket_id]\n    \n    def get_logs_for_actor(self, actor: str) -> List[AuditLog]:\n        \"\"\"Get all audit logs for an actor.\"\"\"\n        return [log for log in self._logs if log.actor == actor]\n    \n    def get_recent_logs(self, limit: int = 100) -> List[AuditLog]:\n        \"\"\"Get recent audit logs.\"\"\"\n        return sorted(self._logs, key=lambda x: x.timestamp, reverse=True)[:limit]\n    \n    def clear(self) -> None:\n        \"\"\"Clear all audit logs.\"\"\"\n        self._logs.clear()\n\n\n\n===== FILE: src\\helpdesk_ai\\services\\escalation.py =====\n\"\"\"\nEscalation service for handling ticket escalations.\n\"\"\"\n\nfrom typing import List, Optional\nfrom datetime import datetime, timedelta\nfrom ..domain.models import Ticket, TicketStatus, Priority\n\n\nclass EscalationService:\n    \"\"\"Service for managing ticket escalations.\"\"\"\n    \n    def __init__(\n        self,\n        escalation_threshold_hours: int = 24,\n        auto_escalate_critical: bool = True,\n    ):\n        \"\"\"Initialize escalation service.\"\"\"\n        self.escalation_threshold_hours = escalation_threshold_hours\n        self.auto_escalate_critical = auto_escalate_critical\n    \n    def should_escalate(self, ticket: Ticket) -> bool:\n        \"\"\"Check if a ticket should be escalated.\"\"\"\n        # Auto-escalate critical tickets\n        if self.auto_escalate_critical and ticket.priority == Priority.CRITICAL:\n            if ticket.status not in [TicketStatus.RESOLVED, TicketStatus.CLOSED]:\n                return True\n        \n        # Escalate based on age\n        age = datetime.now() - ticket.created_at\n        if age > timedelta(hours=self.escalation_threshold_hours):\n            if ticket.status not in [TicketStatus.RESOLVED, TicketStatus.CLOSED]:\n                return True\n        \n        return False\n    \n    def escalate(self, ticket: Ticket, reason: Optional[str] = None) -> Ticket:\n        \"\"\"Escalate a ticket.\"\"\"\n        if ticket.status in [TicketStatus.RESOLVED, TicketStatus.CLOSED]:\n            return ticket\n        \n        # Increase priority if not already critical\n        if ticket.priority != Priority.CRITICAL:\n            if ticket.priority == Priority.LOW:\n                ticket.priority = Priority.MEDIUM\n            elif ticket.priority == Priority.MEDIUM:\n                ticket.priority = Priority.HIGH\n            elif ticket.priority == Priority.HIGH:\n                ticket.priority = Priority.CRITICAL\n        \n        ticket.status = TicketStatus.ESCALATED\n        ticket.metadata[\"escalated_at\"] = datetime.now().isoformat()\n        if reason:\n            ticket.metadata[\"escalation_reason\"] = reason\n        \n        return ticket\n    \n    def check_and_escalate(self, ticket: Ticket) -> Optional[Ticket]:\n        \"\"\"Check if ticket should be escalated and escalate if needed.\"\"\"\n        if self.should_escalate(ticket):\n            return self.escalate(ticket, \"Automatic escalation due to age or priority\")\n        return None\n    \n    def batch_check(self, tickets: List[Ticket]) -> List[Ticket]:\n        \"\"\"Check multiple tickets for escalation.\"\"\"\n        escalated = []\n        for ticket in tickets:\n            escalated_ticket = self.check_and_escalate(ticket)\n            if escalated_ticket:\n                escalated.append(escalated_ticket)\n        return escalated\n\n\n\n===== FILE: src\\helpdesk_ai\\services\\routing.py =====\n\"\"\"\nRouting service for assigning tickets to appropriate handlers.\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Optional, List\nfrom ..domain.models import Ticket, Priority, Category\nfrom ..domain.rules import RuleEngine, Rule\n\n\n@dataclass\nclass RoutingResult:\n    \"\"\"Result of routing a ticket.\"\"\"\n    \n    ticket: Ticket\n    assigned_to: Optional[str]\n    priority: Priority\n    category: Category\n    rule_matched: Optional[str]\n    confidence: float\n\n\nclass Router:\n    \"\"\"Router for assigning tickets to handlers.\"\"\"\n    \n    def __init__(self, rule_engine: RuleEngine):\n        \"\"\"Initialize router with rule engine.\"\"\"\n        self.rule_engine = rule_engine\n        self.default_assignees = {\n            Category.TECHNICAL: \"tech-team\",\n            Category.BILLING: \"billing-team\",\n            Category.ACCOUNT: \"account-team\",\n            Category.FEATURE: \"product-team\",\n            Category.BUG: \"engineering-team\",\n            Category.GENERAL: \"support-team\",\n        }\n    \n    def route(self, ticket: Ticket) -> RoutingResult:\n        \"\"\"Route a ticket to appropriate handler.\"\"\"\n        # Find matching rule\n        matching_rule = self.rule_engine.get_highest_priority_match(ticket)\n        \n        if matching_rule:\n            # Use rule's assignment if available\n            assigned_to = matching_rule.target_assignee or self.default_assignees.get(ticket.category)\n            priority = matching_rule.priority\n            category = matching_rule.target_category or ticket.category\n            rule_matched = matching_rule.rule_id\n            confidence = 1.0\n        else:\n            # Default routing\n            assigned_to = self.default_assignees.get(ticket.category)\n            priority = ticket.priority\n            category = ticket.category\n            rule_matched = None\n            confidence = 0.5\n        \n        # Update ticket with routing results\n        ticket.update(\n            assigned_to=assigned_to,\n            priority=priority,\n            category=category,\n        )\n        \n        return RoutingResult(\n            ticket=ticket,\n            assigned_to=assigned_to,\n            priority=priority,\n            category=category,\n            rule_matched=rule_matched,\n            confidence=confidence,\n        )\n    \n    def batch_route(self, tickets: List[Ticket]) -> List[RoutingResult]:\n        \"\"\"Route multiple tickets.\"\"\"\n        return [self.route(ticket) for ticket in tickets]\n\n\n\n===== FILE: src\\helpdesk_ai\\services\\triage.py =====\n\"\"\"\nTriage service for processing and scoring tickets.\n\"\"\"\n\nfrom typing import List, Optional\nfrom ..domain.models import Ticket\nfrom ..domain.scoring import Scorer, Score\nfrom ..domain.rules import RuleEngine\nfrom .routing import Router, RoutingResult\n\n\nclass TriageService:\n    \"\"\"Service for triaging tickets.\"\"\"\n    \n    def __init__(\n        self,\n        scorer: Scorer,\n        router: Router,\n        rule_engine: Optional[RuleEngine] = None,\n    ):\n        \"\"\"Initialize triage service.\"\"\"\n        self.scorer = scorer\n        self.router = router\n        self.rule_engine = rule_engine or Router.rule_engine if hasattr(Router, 'rule_engine') else None\n    \n    def triage(self, ticket: Ticket) -> RoutingResult:\n        \"\"\"Triage a single ticket.\"\"\"\n        # Score the ticket\n        score = self.scorer.score(ticket)\n        ticket.score = score.normalized if score.normalized is not None else score.total\n        \n        # Route the ticket\n        routing_result = self.router.route(ticket)\n        \n        return routing_result\n    \n    def batch_triage(self, tickets: List[Ticket]) -> List[RoutingResult]:\n        \"\"\"Triage multiple tickets.\"\"\"\n        results = []\n        for ticket in tickets:\n            result = self.triage(ticket)\n            results.append(result)\n        return results\n    \n    def get_score(self, ticket: Ticket) -> Score:\n        \"\"\"Get score for a ticket without routing.\"\"\"\n        return self.scorer.score(ticket)\n\n\n\n===== FILE: src\\helpdesk_ai\\services\\__init__.py =====\n\"\"\"Service layer for ticket processing.\"\"\"\n\nfrom .routing import Router, RoutingResult\nfrom .triage import TriageService\nfrom .escalation import EscalationService\nfrom .audit import AuditService, AuditLog\n\n__all__ = [\n    \"Router\",\n    \"RoutingResult\",\n    \"TriageService\",\n    \"EscalationService\",\n    \"AuditService\",\n    \"AuditLog\",\n]\n\n\n\n===== FILE: src\\helpdesk_ai\\store\\cache.py =====\n\"\"\"\nCaching layer for ticket operations.\n\"\"\"\n\nfrom typing import Optional, Dict, Any, Callable\nfrom datetime import datetime, timedelta\nfrom ..domain.models import Ticket\n\n\nclass Cache:\n    \"\"\"Base cache interface.\"\"\"\n    \n    def get(self, key: str) -> Optional[Any]:\n        \"\"\"Get value from cache.\"\"\"\n        raise NotImplementedError\n    \n    def set(self, key: str, value: Any, ttl: Optional[int] = None) -> None:\n        \"\"\"Set value in cache.\"\"\"\n        raise NotImplementedError\n    \n    def delete(self, key: str) -> None:\n        \"\"\"Delete value from cache.\"\"\"\n        raise NotImplementedError\n    \n    def clear(self) -> None:\n        \"\"\"Clear all cache entries.\"\"\"\n        raise NotImplementedError\n\n\nclass CacheEntry:\n    \"\"\"Represents a cache entry with expiration.\"\"\"\n    \n    def __init__(self, value: Any, ttl: Optional[int] = None):\n        \"\"\"Initialize cache entry.\"\"\"\n        self.value = value\n        self.created_at = datetime.now()\n        self.ttl = ttl\n        if ttl:\n            self.expires_at = self.created_at + timedelta(seconds=ttl)\n        else:\n            self.expires_at = None\n    \n    def is_expired(self) -> bool:\n        \"\"\"Check if entry is expired.\"\"\"\n        if self.expires_at is None:\n            return False\n        return datetime.now() > self.expires_at\n\n\nclass MemoryCache(Cache):\n    \"\"\"In-memory cache implementation.\"\"\"\n    \n    def __init__(self, default_ttl: Optional[int] = None):\n        \"\"\"Initialize memory cache.\"\"\"\n        self._entries: Dict[str, CacheEntry] = {}\n        self.default_ttl = default_ttl\n    \n    def get(self, key: str) -> Optional[Any]:\n        \"\"\"Get value from cache.\"\"\"\n        entry = self._entries.get(key)\n        if entry is None:\n            return None\n        \n        if entry.is_expired():\n            del self._entries[key]\n            return None\n        \n        return entry.value\n    \n    def set(self, key: str, value: Any, ttl: Optional[int] = None) -> None:\n        \"\"\"Set value in cache.\"\"\"\n        ttl = ttl or self.default_ttl\n        self._entries[key] = CacheEntry(value, ttl)\n    \n    def delete(self, key: str) -> None:\n        \"\"\"Delete value from cache.\"\"\"\n        if key in self._entries:\n            del self._entries[key]\n    \n    def clear(self) -> None:\n        \"\"\"Clear all cache entries.\"\"\"\n        self._entries.clear()\n    \n    def _generate_key(self, prefix: str, **kwargs) -> str:\n        \"\"\"\n        Generate cache key from prefix and kwargs.\n        \n        BUG: Key collision - two different requests can map to the same key.\n        When kwargs contain nested dicts or lists, they're converted to string\n        which can cause collisions. Also, order of kwargs matters but isn't\n        normalized, so same data in different order creates different keys.\n        \"\"\"\n        # Convert kwargs to string representation\n        # BUG: This doesn't handle nested structures properly\n        # BUG: Order of kwargs affects key generation\n        parts = [prefix]\n        for k, v in sorted(kwargs.items()):\n            # BUG: str(dict) or str(list) can create same string for different objects\n            parts.append(f\"{k}={str(v)}\")\n        return \":\".join(parts)\n    \n    def cache_ticket(self, ticket: Ticket) -> str:\n        \"\"\"Cache a ticket and return its key.\"\"\"\n        # BUG: This key generation can collide\n        # Two tickets with same email and category but different IDs get same key\n        key = self._generate_key(\n            \"ticket\",\n            email=ticket.requester_email,\n            category=ticket.category.value,\n            # BUG: ticket_id not included, causing potential collisions\n        )\n        self.set(key, ticket)\n        return key\n    \n    def get_cached_ticket(self, email: str, category: str) -> Optional[Ticket]:\n        \"\"\"Get cached ticket by email and category.\"\"\"\n        key = self._generate_key(\"ticket\", email=email, category=category)\n        return self.get(key)\n\n\n\n===== FILE: src\\helpdesk_ai\\store\\file_store.py =====\n\"\"\"\nFile-based storage implementation for tickets.\n\"\"\"\n\nimport json\nimport os\nfrom pathlib import Path\nfrom typing import Optional, List\nfrom ..domain.models import Ticket\n\n\nclass FileStore:\n    \"\"\"File-based ticket storage.\"\"\"\n    \n    def __init__(self, base_path: str):\n        \"\"\"Initialize file store with base path.\"\"\"\n        self.base_path = Path(base_path)\n        self.base_path.mkdir(parents=True, exist_ok=True)\n        self.tickets_dir = self.base_path / \"tickets\"\n        self.tickets_dir.mkdir(exist_ok=True)\n    \n    def _ticket_path(self, ticket_id: str) -> Path:\n        \"\"\"Get file path for a ticket.\"\"\"\n        return self.tickets_dir / f\"{ticket_id}.json\"\n    \n    def save(self, ticket: Ticket) -> None:\n        \"\"\"Save a ticket to file.\"\"\"\n        path = self._ticket_path(ticket.ticket_id)\n        with open(path, \"w\") as f:\n            json.dump(ticket.to_dict(), f, indent=2)\n    \n    def get(self, ticket_id: str) -> Optional[Ticket]:\n        \"\"\"Get a ticket by ID.\"\"\"\n        path = self._ticket_path(ticket_id)\n        if not path.exists():\n            return None\n        \n        try:\n            with open(path, \"r\") as f:\n                data = json.load(f)\n            return Ticket.from_dict(data)\n        except Exception:\n            return None\n    \n    def delete(self, ticket_id: str) -> bool:\n        \"\"\"Delete a ticket by ID. Returns True if deleted.\"\"\"\n        path = self._ticket_path(ticket_id)\n        if path.exists():\n            path.unlink()\n            return True\n        return False\n    \n    def list_all(self) -> List[Ticket]:\n        \"\"\"List all tickets.\"\"\"\n        tickets = []\n        for path in self.tickets_dir.glob(\"*.json\"):\n            try:\n                ticket_id = path.stem\n                ticket = self.get(ticket_id)\n                if ticket:\n                    tickets.append(ticket)\n            except Exception:\n                continue\n        return tickets\n    \n    def count(self) -> int:\n        \"\"\"Get total number of tickets.\"\"\"\n        return len(list(self.tickets_dir.glob(\"*.json\")))\n\n\n\n===== FILE: src\\helpdesk_ai\\store\\memory_store.py =====\n\"\"\"\nIn-memory storage implementation for tickets.\n\"\"\"\n\nfrom typing import Dict, Optional, List\nfrom ..domain.models import Ticket\n\n\nclass MemoryStore:\n    \"\"\"In-memory ticket storage.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize memory store.\"\"\"\n        self._tickets: Dict[str, Ticket] = {}\n    \n    def save(self, ticket: Ticket) -> None:\n        \"\"\"Save a ticket.\"\"\"\n        self._tickets[ticket.ticket_id] = ticket\n    \n    def get(self, ticket_id: str) -> Optional[Ticket]:\n        \"\"\"Get a ticket by ID.\"\"\"\n        return self._tickets.get(ticket_id)\n    \n    def delete(self, ticket_id: str) -> bool:\n        \"\"\"Delete a ticket by ID. Returns True if deleted.\"\"\"\n        if ticket_id in self._tickets:\n            del self._tickets[ticket_id]\n            return True\n        return False\n    \n    def list_all(self) -> List[Ticket]:\n        \"\"\"List all tickets.\"\"\"\n        return list(self._tickets.values())\n    \n    def search(self, **criteria) -> List[Ticket]:\n        \"\"\"Search tickets by criteria.\"\"\"\n        results = []\n        for ticket in self._tickets.values():\n            match = True\n            for key, value in criteria.items():\n                if not hasattr(ticket, key):\n                    match = False\n                    break\n                if getattr(ticket, key) != value:\n                    match = False\n                    break\n            if match:\n                results.append(ticket)\n        return results\n    \n    def count(self) -> int:\n        \"\"\"Get total number of tickets.\"\"\"\n        return len(self._tickets)\n    \n    def clear(self) -> None:\n        \"\"\"Clear all tickets.\"\"\"\n        self._tickets.clear()\n\n\n\n===== FILE: src\\helpdesk_ai\\store\\__init__.py =====\n\"\"\"Storage modules for tickets.\"\"\"\n\nfrom .memory_store import MemoryStore\nfrom .file_store import FileStore\nfrom .cache import Cache, MemoryCache\n\n__all__ = [\n    \"MemoryStore\",\n    \"FileStore\",\n    \"Cache\",\n    \"MemoryCache\",\n]\n\n\n\n===== FILE: src\\helpdesk_ai\\utils\\errors.py =====\n\"\"\"\nCustom exception classes.\n\"\"\"\n\n\nclass HelpdeskError(Exception):\n    \"\"\"Base exception for helpdesk operations.\"\"\"\n    pass\n\n\nclass ValidationError(HelpdeskError):\n    \"\"\"Raised when validation fails.\"\"\"\n    pass\n\n\nclass StorageError(HelpdeskError):\n    \"\"\"Raised when storage operations fail.\"\"\"\n    pass\n\n\nclass RoutingError(HelpdeskError):\n    \"\"\"Raised when routing fails.\"\"\"\n    pass\n\n\nclass ScoringError(HelpdeskError):\n    \"\"\"Raised when scoring fails.\"\"\"\n    pass\n\n\nclass ParsingError(HelpdeskError):\n    \"\"\"Raised when parsing fails.\"\"\"\n    pass\n\n\n\n===== FILE: src\\helpdesk_ai\\utils\\ids.py =====\n\"\"\"\nID generation utilities.\n\"\"\"\n\nimport uuid\nfrom datetime import datetime\n\n\ndef generate_ticket_id(prefix: str = \"TKT\") -> str:\n    \"\"\"Generate a unique ticket ID.\"\"\"\n    timestamp = datetime.now().strftime(\"%Y%m%d\")\n    unique_part = str(uuid.uuid4())[:8].upper()\n    return f\"{prefix}-{timestamp}-{unique_part}\"\n\n\ndef generate_audit_id(prefix: str = \"AUD\") -> str:\n    \"\"\"Generate a unique audit log ID.\"\"\"\n    timestamp = datetime.now().strftime(\"%Y%m%d\")\n    unique_part = str(uuid.uuid4())[:8].upper()\n    return f\"{prefix}-{timestamp}-{unique_part}\"\n\n\ndef generate_session_id() -> str:\n    \"\"\"Generate a unique session ID.\"\"\"\n    return str(uuid.uuid4())\n\n\ndef is_valid_ticket_id(ticket_id: str) -> bool:\n    \"\"\"Validate ticket ID format.\"\"\"\n    parts = ticket_id.split(\"-\")\n    if len(parts) != 3:\n        return False\n    prefix, date_part, unique_part = parts\n    if len(date_part) != 8 or not date_part.isdigit():\n        return False\n    if len(unique_part) != 8:\n        return False\n    return True\n\n\n\n===== FILE: src\\helpdesk_ai\\utils\\text.py =====\n\"\"\"\nText utility functions.\n\"\"\"\n\nimport re\nfrom typing import Optional, List\n\n\ndef normalize_text(text: str) -> str:\n    \"\"\"Normalize text by removing extra whitespace and normalizing line breaks.\"\"\"\n    if not text:\n        return \"\"\n    \n    # Replace multiple whitespace with single space\n    text = re.sub(r'\\s+', ' ', text)\n    # Normalize line breaks\n    text = re.sub(r'\\r\\n', '\\n', text)\n    text = re.sub(r'\\r', '\\n', text)\n    # Remove trailing whitespace\n    text = text.strip()\n    \n    return text\n\n\ndef extract_email(text: str) -> Optional[str]:\n    \"\"\"Extract email address from text.\"\"\"\n    email_pattern = re.compile(r'\\b[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\\b')\n    match = email_pattern.search(text)\n    return match.group(0) if match else None\n\n\ndef truncate_text(text: str, max_length: int, suffix: str = \"...\") -> str:\n    \"\"\"Truncate text to maximum length.\"\"\"\n    if len(text) <= max_length:\n        return text\n    return text[:max_length - len(suffix)] + suffix\n\n\ndef extract_keywords(text: str, min_length: int = 3) -> List[str]:\n    \"\"\"Extract keywords from text.\"\"\"\n    # Simple keyword extraction - words that are not common stop words\n    stop_words = {\n        \"the\", \"a\", \"an\", \"and\", \"or\", \"but\", \"in\", \"on\", \"at\", \"to\", \"for\",\n        \"of\", \"with\", \"by\", \"from\", \"as\", \"is\", \"was\", \"are\", \"were\", \"be\",\n        \"been\", \"have\", \"has\", \"had\", \"do\", \"does\", \"did\", \"will\", \"would\",\n        \"should\", \"could\", \"may\", \"might\", \"must\", \"can\", \"this\", \"that\",\n        \"these\", \"those\", \"i\", \"you\", \"he\", \"she\", \"it\", \"we\", \"they\",\n    }\n    \n    words = re.findall(r'\\b[a-zA-Z]+\\b', text.lower())\n    keywords = [w for w in words if len(w) >= min_length and w not in stop_words]\n    \n    # Remove duplicates while preserving order\n    seen = set()\n    unique_keywords = []\n    for kw in keywords:\n        if kw not in seen:\n            seen.add(kw)\n            unique_keywords.append(kw)\n    \n    return unique_keywords\n\n\ndef sanitize_filename(text: str) -> str:\n    \"\"\"Sanitize text for use as filename.\"\"\"\n    # Replace invalid characters with underscore\n    sanitized = re.sub(r'[<>:\"/\\\\|?*]', '_', text)\n    # Remove leading/trailing dots and spaces\n    sanitized = sanitized.strip('. ')\n    # Limit length\n    if len(sanitized) > 255:\n        sanitized = sanitized[:255]\n    return sanitized\n\n\n\n===== FILE: src\\helpdesk_ai\\utils\\time.py =====\n\"\"\"\nTime utility functions.\n\"\"\"\n\nfrom datetime import datetime, timedelta\nfrom typing import Optional\n\n\ndef format_timestamp(dt: datetime, format_str: Optional[str] = None) -> str:\n    \"\"\"Format datetime to string.\"\"\"\n    if format_str is None:\n        format_str = \"%Y-%m-%d %H:%M:%S\"\n    return dt.strftime(format_str)\n\n\ndef parse_timestamp(timestamp_str: str, format_str: Optional[str] = None) -> datetime:\n    \"\"\"Parse string to datetime.\"\"\"\n    if format_str is None:\n        # Try ISO format first\n        try:\n            return datetime.fromisoformat(timestamp_str)\n        except ValueError:\n            format_str = \"%Y-%m-%d %H:%M:%S\"\n    \n    return datetime.strptime(timestamp_str, format_str)\n\n\ndef time_ago(dt: datetime) -> str:\n    \"\"\"Get human-readable time ago string.\"\"\"\n    delta = datetime.now() - dt\n    \n    if delta.days > 365:\n        years = delta.days // 365\n        return f\"{years} year{'s' if years != 1 else ''} ago\"\n    elif delta.days > 30:\n        months = delta.days // 30\n        return f\"{months} month{'s' if months != 1 else ''} ago\"\n    elif delta.days > 0:\n        return f\"{delta.days} day{'s' if delta.days != 1 else ''} ago\"\n    elif delta.seconds > 3600:\n        hours = delta.seconds // 3600\n        return f\"{hours} hour{'s' if hours != 1 else ''} ago\"\n    elif delta.seconds > 60:\n        minutes = delta.seconds // 60\n        return f\"{minutes} minute{'s' if minutes != 1 else ''} ago\"\n    else:\n        return \"just now\"\n\n\ndef is_business_hours(dt: datetime) -> bool:\n    \"\"\"Check if datetime is within business hours (9 AM - 5 PM, Mon-Fri).\"\"\"\n    if dt.weekday() >= 5:  # Saturday or Sunday\n        return False\n    return 9 <= dt.hour < 17\n\n\ndef add_business_days(dt: datetime, days: int) -> datetime:\n    \"\"\"Add business days to a datetime.\"\"\"\n    current = dt\n    added = 0\n    while added < days:\n        current += timedelta(days=1)\n        if is_business_hours(current):\n            added += 1\n    return current\n\n\n\n===== FILE: src\\helpdesk_ai\\utils\\__init__.py =====\n\"\"\"Utility modules.\"\"\"\n\nfrom .time import format_timestamp, parse_timestamp, time_ago\nfrom .text import normalize_text, extract_email, truncate_text\nfrom .ids import generate_ticket_id, generate_audit_id\nfrom .errors import HelpdeskError, ValidationError, StorageError\n\n__all__ = [\n    \"format_timestamp\",\n    \"parse_timestamp\",\n    \"time_ago\",\n    \"normalize_text\",\n    \"extract_email\",\n    \"truncate_text\",\n    \"generate_ticket_id\",\n    \"generate_audit_id\",\n    \"HelpdeskError\",\n    \"ValidationError\",\n    \"StorageError\",\n]\n\n\n\n===== FILE: src\\helpdesk_ai\\web\\app.py =====\n\"\"\"\nMinimal web application skeleton for helpdesk service.\n\"\"\"\n\nfrom typing import Dict, Any, Optional\nfrom .handlers import TicketHandler, HealthHandler\n\n\nclass WebApp:\n    \"\"\"Minimal WSGI-like web application.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize web application.\"\"\"\n        self.handlers = {\n            \"/health\": HealthHandler(),\n            \"/tickets\": TicketHandler(),\n        }\n    \n    def handle_request(self, path: str, method: str = \"GET\", body: Optional[str] = None) -> Dict[str, Any]:\n        \"\"\"Handle a web request.\"\"\"\n        handler = self.handlers.get(path)\n        if not handler:\n            return {\n                \"status\": 404,\n                \"headers\": {\"Content-Type\": \"application/json\"},\n                \"body\": '{\"error\": \"Not found\"}',\n            }\n        \n        if method == \"GET\":\n            return handler.get()\n        elif method == \"POST\":\n            return handler.post(body)\n        elif method == \"PUT\":\n            return handler.put(body)\n        elif method == \"DELETE\":\n            return handler.delete()\n        else:\n            return {\n                \"status\": 405,\n                \"headers\": {\"Content-Type\": \"application/json\"},\n                \"body\": '{\"error\": \"Method not allowed\"}',\n            }\n\n\ndef create_app() -> WebApp:\n    \"\"\"Create and configure web application.\"\"\"\n    return WebApp()\n\n\n\n===== FILE: src\\helpdesk_ai\\web\\handlers.py =====\n\"\"\"\nRequest handlers for web interface.\n\"\"\"\n\nimport json\nfrom typing import Dict, Any, Optional\nfrom ..store.memory_store import MemoryStore\nfrom ..services.triage import TriageService\nfrom ..cli import create_default_triage_service\n\n\nclass Handler:\n    \"\"\"Base handler class.\"\"\"\n    \n    def get(self) -> Dict[str, Any]:\n        \"\"\"Handle GET request.\"\"\"\n        return {\n            \"status\": 405,\n            \"headers\": {\"Content-Type\": \"application/json\"},\n            \"body\": '{\"error\": \"Method not allowed\"}',\n        }\n    \n    def post(self, body: Optional[str] = None) -> Dict[str, Any]:\n        \"\"\"Handle POST request.\"\"\"\n        return {\n            \"status\": 405,\n            \"headers\": {\"Content-Type\": \"application/json\"},\n            \"body\": '{\"error\": \"Method not allowed\"}',\n        }\n    \n    def put(self, body: Optional[str] = None) -> Dict[str, Any]:\n        \"\"\"Handle PUT request.\"\"\"\n        return {\n            \"status\": 405,\n            \"headers\": {\"Content-Type\": \"application/json\"},\n            \"body\": '{\"error\": \"Method not allowed\"}',\n        }\n    \n    def delete(self) -> Dict[str, Any]:\n        \"\"\"Handle DELETE request.\"\"\"\n        return {\n            \"status\": 405,\n            \"headers\": {\"Content-Type\": \"application/json\"},\n            \"body\": '{\"error\": \"Method not allowed\"}',\n        }\n\n\nclass HealthHandler(Handler):\n    \"\"\"Health check handler.\"\"\"\n    \n    def get(self) -> Dict[str, Any]:\n        \"\"\"Handle health check request.\"\"\"\n        return {\n            \"status\": 200,\n            \"headers\": {\"Content-Type\": \"application/json\"},\n            \"body\": json.dumps({\"status\": \"healthy\"}),\n        }\n\n\nclass TicketHandler(Handler):\n    \"\"\"Ticket management handler.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize ticket handler.\"\"\"\n        self.store = MemoryStore()\n        self.triage_service = create_default_triage_service()\n    \n    def get(self) -> Dict[str, Any]:\n        \"\"\"Get all tickets.\"\"\"\n        tickets = self.store.list_all()\n        tickets_data = [t.to_dict() for t in tickets]\n        return {\n            \"status\": 200,\n            \"headers\": {\"Content-Type\": \"application/json\"},\n            \"body\": json.dumps({\"tickets\": tickets_data}),\n        }\n    \n    def post(self, body: Optional[str] = None) -> Dict[str, Any]:\n        \"\"\"Create a new ticket.\"\"\"\n        if not body:\n            return {\n                \"status\": 400,\n                \"headers\": {\"Content-Type\": \"application/json\"},\n                \"body\": json.dumps({\"error\": \"Request body required\"}),\n            }\n        \n        try:\n            data = json.loads(body)\n            # In a real implementation, we'd parse, validate, normalize, and triage here\n            # For this skeleton, we just return a success response\n            return {\n                \"status\": 201,\n                \"headers\": {\"Content-Type\": \"application/json\"},\n                \"body\": json.dumps({\"message\": \"Ticket created\", \"data\": data}),\n            }\n        except json.JSONDecodeError:\n            return {\n                \"status\": 400,\n                \"headers\": {\"Content-Type\": \"application/json\"},\n                \"body\": json.dumps({\"error\": \"Invalid JSON\"}),\n            }\n\n\n\n===== FILE: src\\helpdesk_ai\\web\\__init__.py =====\n\"\"\"Web interface modules.\"\"\"\n\nfrom .app import create_app\nfrom .handlers import TicketHandler, HealthHandler\n\n__all__ = [\n    \"create_app\",\n    \"TicketHandler\",\n    \"HealthHandler\",\n]\n\n\n\n===== FILE: tests\\test_parsers.py =====\n\"\"\"\nTests for parsers and validators.\n\nThese tests expose bugs in validation logic.\n\"\"\"\n\nimport pytest\nfrom helpdesk_ai.ingest.parsers import JSONParser, CSVParser, TextParser\nfrom helpdesk_ai.ingest.validators import TicketValidator, ValidationError\nfrom helpdesk_ai.ingest.normalize import TicketNormalizer\n\n\ndef test_json_parser():\n    \"\"\"Test JSON parsing.\"\"\"\n    parser = JSONParser()\n    \n    data = '{\"ticket_id\": \"TKT-001\", \"title\": \"Test\", \"description\": \"Test desc\", \"requester_email\": \"test@example.com\"}'\n    result = parser.parse(data)\n    \n    assert result[\"ticket_id\"] == \"TKT-001\"\n    assert result[\"title\"] == \"Test\"\n\n\ndef test_validator_required_fields():\n    \"\"\"Test validation of required fields.\"\"\"\n    validator = TicketValidator()\n    \n    # Missing required fields\n    data = {}\n    errors = validator.validate(data)\n    \n    assert len(errors) > 0\n    error_fields = {e.field for e in errors}\n    assert \"ticket_id\" in error_fields\n    assert \"title\" in error_fields\n    assert \"requester_email\" in error_fields\n\n\ndef test_validator_description_bug():\n    \"\"\"\n    Test that exposes validator bug with description field.\n    \n    BUG: When data has \"body\" field but not \"description\", validation\n    doesn't properly validate the \"body\" field.\n    \"\"\"\n    validator = TicketValidator()\n    \n    # Data with \"body\" instead of \"description\"\n    data = {\n        \"ticket_id\": \"TKT-001\",\n        \"title\": \"Test ticket\",\n        \"body\": \"\",  # Empty body should fail validation\n        \"requester_email\": \"test@example.com\",\n    }\n    \n    errors = validator.validate(data)\n    \n    # BUG: This should catch empty \"body\" field, but validator may miss it\n    description_errors = [e for e in errors if \"description\" in e.message.lower() or e.field == \"description\"]\n    assert len(description_errors) > 0, \"Should validate description/body field\"\n\n\ndef test_validator_partial_validation_bug():\n    \"\"\"\n    Test that exposes bug in partial validation.\n    \n    BUG: validate_partial doesn't validate description at all, even when provided.\n    \"\"\"\n    validator = TicketValidator()\n    \n    # Partial update with description\n    data = {\n        \"description\": \"\",  # Empty description should fail\n    }\n    \n    errors = validator.validate_partial(data)\n    \n    # BUG: Should validate description if present, but currently doesn't\n    description_errors = [e for e in errors if \"description\" in e.message.lower() or e.field == \"description\"]\n    # This assertion will fail because description validation is missing\n    assert len(description_errors) > 0, \"Should validate description in partial updates\"\n\n\ndef test_validator_email_format():\n    \"\"\"Test email format validation.\"\"\"\n    validator = TicketValidator()\n    \n    data = {\n        \"ticket_id\": \"TKT-001\",\n        \"title\": \"Test\",\n        \"description\": \"Test desc\",\n        \"requester_email\": \"invalid-email\",  # Invalid format\n    }\n    \n    errors = validator.validate(data)\n    email_errors = [e for e in errors if e.field == \"requester_email\"]\n    assert len(email_errors) > 0\n\n\ndef test_normalizer_body_to_description():\n    \"\"\"Test that normalizer handles \"body\" field.\"\"\"\n    normalizer = TicketNormalizer()\n    \n    data = {\n        \"ticket_id\": \"TKT-001\",\n        \"title\": \"Test\",\n        \"body\": \"Test description\",  # Using \"body\" instead of \"description\"\n        \"requester_email\": \"test@example.com\",\n    }\n    \n    ticket = normalizer.normalize(data)\n    assert ticket.description == \"Test description\"\n\n\ndef test_csv_parser():\n    \"\"\"Test CSV parsing.\"\"\"\n    parser = CSVParser(has_header=True)\n    \n    data = \"ticket_id,title,description,requester_email\\nTKT-001,Test,Test desc,test@example.com\"\n    result = parser.parse(data)\n    \n    assert result[\"ticket_id\"] == \"TKT-001\"\n    assert result[\"title\"] == \"Test\"\n\n\n\n===== FILE: tests\\test_routing.py =====\n\"\"\"\nTests for routing and cache functionality.\n\nThese tests expose bugs in cache key generation and routing.\n\"\"\"\n\nimport pytest\nfrom helpdesk_ai.domain.models import Ticket, Category, Priority\nfrom helpdesk_ai.store.cache import MemoryCache\nfrom helpdesk_ai.services.routing import Router\nfrom helpdesk_ai.domain.rules import RuleEngine\n\n\ndef test_cache_key_collision_bug():\n    \"\"\"\n    Test that exposes cache key collision bug.\n    \n    BUG: Two different tickets with same email and category but different\n    IDs can map to the same cache key because ticket_id is not included.\n    \"\"\"\n    cache = MemoryCache()\n    \n    ticket1 = Ticket(\n        ticket_id=\"TKT-001\",\n        title=\"First ticket\",\n        description=\"First description\",\n        requester_email=\"user@example.com\",\n        category=Category.BILLING,\n    )\n    \n    ticket2 = Ticket(\n        ticket_id=\"TKT-002\",  # Different ID\n        title=\"Second ticket\",\n        description=\"Second description\",\n        requester_email=\"user@example.com\",  # Same email\n        category=Category.BILLING,  # Same category\n    )\n    \n    # Cache both tickets\n    key1 = cache.cache_ticket(ticket1)\n    key2 = cache.cache_ticket(ticket2)\n    \n    # BUG: Keys should be different but may collide\n    assert key1 != key2, \"Cache keys should be unique for different tickets\"\n    \n    # Verify we can retrieve the correct ticket\n    cached1 = cache.get_cached_ticket(\"user@example.com\", \"billing\")\n    # BUG: This may return ticket2 instead of ticket1 due to collision\n    assert cached1 is not None\n    # Should be able to distinguish between tickets\n    assert cached1.ticket_id in [\"TKT-001\", \"TKT-002\"]\n\n\ndef test_cache_key_generation_order():\n    \"\"\"Test that cache key generation handles different kwarg orders.\"\"\"\n    cache = MemoryCache()\n    \n    # Same data, different order\n    key1 = cache._generate_key(\"test\", a=1, b=2)\n    key2 = cache._generate_key(\"test\", b=2, a=1)\n    \n    # Should generate same key (sorted)\n    assert key1 == key2\n\n\ndef test_cache_key_with_nested_structures():\n    \"\"\"Test cache key generation with nested structures.\"\"\"\n    cache = MemoryCache()\n    \n    # BUG: Nested dicts/lists may create same string representation\n    key1 = cache._generate_key(\"test\", data={\"a\": 1, \"b\": 2})\n    key2 = cache._generate_key(\"test\", data={\"b\": 2, \"a\": 1})  # Different dict, same content\n    \n    # These might collide incorrectly\n    # In a proper implementation, should serialize deterministically\n    assert isinstance(key1, str)\n    assert isinstance(key2, str)\n\n\ndef test_router_priority_assignment():\n    \"\"\"Test router priority assignment.\"\"\"\n    rule_engine = RuleEngine()\n    \n    rule_engine.add_rule(Rule(\n        rule_id=\"high_priority_rule\",\n        name=\"High Priority\",\n        priority=Priority.HIGH,\n        condition=lambda t: True,\n    ))\n    \n    router = Router(rule_engine)\n    \n    ticket = Ticket(\n        ticket_id=\"TKT-001\",\n        title=\"Test\",\n        description=\"Test\",\n        requester_email=\"test@example.com\",\n        category=Category.GENERAL,\n        priority=Priority.LOW,\n    )\n    \n    result = router.route(ticket)\n    \n    # Router should assign priority from rule\n    assert result.priority == Priority.HIGH\n\n\ndef test_router_default_assignment():\n    \"\"\"Test router default assignment when no rules match.\"\"\"\n    rule_engine = RuleEngine()\n    router = Router(rule_engine)\n    \n    ticket = Ticket(\n        ticket_id=\"TKT-001\",\n        title=\"Test\",\n        description=\"Test\",\n        requester_email=\"test@example.com\",\n        category=Category.TECHNICAL,\n        priority=Priority.MEDIUM,\n    )\n    \n    result = router.route(ticket)\n    \n    # Should use default assignee for category\n    assert result.assigned_to == \"tech-team\"\n    assert result.priority == Priority.MEDIUM\n\n\n\n===== FILE: tests\\test_rules.py =====\n\"\"\"\nTests for rule engine and routing.\n\nThese tests expose bugs in routing priority handling.\n\"\"\"\n\nimport pytest\nfrom helpdesk_ai.domain.models import Ticket, Category, Priority, TicketStatus\nfrom helpdesk_ai.domain.rules import RuleEngine, Rule\n\n\ndef test_rule_matching():\n    \"\"\"Test basic rule matching.\"\"\"\n    rule_engine = RuleEngine()\n    \n    rule = Rule(\n        rule_id=\"test_rule\",\n        name=\"Test Rule\",\n        priority=Priority.HIGH,\n        condition=lambda t: \"test\" in t.title.lower(),\n    )\n    \n    rule_engine.add_rule(rule)\n    \n    ticket = Ticket(\n        ticket_id=\"TKT-001\",\n        title=\"Test ticket\",\n        description=\"Test description\",\n        requester_email=\"test@example.com\",\n        category=Category.GENERAL,\n    )\n    \n    matches = rule_engine.evaluate(ticket)\n    assert len(matches) == 1\n    assert matches[0].matched is True\n\n\ndef test_highest_priority_match_bug():\n    \"\"\"\n    Test that exposes routing priority bug.\n    \n    BUG: get_highest_priority_match returns the LAST match after sorting,\n    which means LOW priority wins instead of CRITICAL.\n    \"\"\"\n    rule_engine = RuleEngine()\n    \n    # Add rules with different priorities\n    rule_engine.add_rule(Rule(\n        rule_id=\"low_priority\",\n        name=\"Low Priority Rule\",\n        priority=Priority.LOW,\n        condition=lambda t: True,  # Always matches\n    ))\n    \n    rule_engine.add_rule(Rule(\n        rule_id=\"critical_priority\",\n        name=\"Critical Priority Rule\",\n        priority=Priority.CRITICAL,\n        condition=lambda t: True,  # Always matches\n    ))\n    \n    ticket = Ticket(\n        ticket_id=\"TKT-001\",\n        title=\"Test ticket\",\n        description=\"Test description\",\n        requester_email=\"test@example.com\",\n        category=Category.GENERAL,\n    )\n    \n    # This should return CRITICAL priority rule, but bug returns LOW\n    matched_rule = rule_engine.get_highest_priority_match(ticket)\n    \n    # BUG: This assertion will fail because LOW priority is returned instead of CRITICAL\n    assert matched_rule is not None\n    assert matched_rule.priority == Priority.CRITICAL, \\\n        f\"Expected CRITICAL priority, got {matched_rule.priority}\"\n\n\ndef test_priority_ordering():\n    \"\"\"Test that priority ordering works correctly.\"\"\"\n    rule_engine = RuleEngine()\n    \n    priorities = [Priority.LOW, Priority.MEDIUM, Priority.HIGH, Priority.CRITICAL]\n    \n    for priority in priorities:\n        rule_engine.add_rule(Rule(\n            rule_id=f\"rule_{priority.value}\",\n            name=f\"{priority.value} Rule\",\n            priority=priority,\n            condition=lambda t: True,\n        ))\n    \n    ticket = Ticket(\n        ticket_id=\"TKT-001\",\n        title=\"Test ticket\",\n        description=\"Test description\",\n        requester_email=\"test@example.com\",\n        category=Category.GENERAL,\n    )\n    \n    matched_rule = rule_engine.get_highest_priority_match(ticket)\n    \n    # Should get CRITICAL, not LOW\n    assert matched_rule.priority == Priority.CRITICAL\n\n\ndef test_multiple_matching_rules():\n    \"\"\"Test behavior with multiple matching rules.\"\"\"\n    rule_engine = RuleEngine()\n    \n    rule_engine.add_rule(Rule(\n        rule_id=\"billing_rule\",\n        name=\"Billing Rule\",\n        priority=Priority.HIGH,\n        condition=lambda t: t.category == Category.BILLING,\n    ))\n    \n    rule_engine.add_rule(Rule(\n        rule_id=\"payment_rule\",\n        name=\"Payment Rule\",\n        priority=Priority.CRITICAL,\n        condition=lambda t: \"payment\" in t.description.lower(),\n    ))\n    \n    ticket = Ticket(\n        ticket_id=\"TKT-001\",\n        title=\"Payment issue\",\n        description=\"Unable to process payment\",\n        requester_email=\"test@example.com\",\n        category=Category.BILLING,\n    )\n    \n    # Both rules should match\n    matches = rule_engine.get_matching_rules(ticket)\n    assert len(matches) == 2\n    \n    # Highest priority should be CRITICAL\n    highest = rule_engine.get_highest_priority_match(ticket)\n    assert highest.priority == Priority.CRITICAL\n\n\n\n===== FILE: tests\\test_scoring.py =====\n\"\"\"\nTests for scoring system.\n\nThese tests expose bugs in scoring normalization.\n\"\"\"\n\nimport pytest\nfrom helpdesk_ai.domain.models import Ticket, Category, Priority\nfrom helpdesk_ai.domain.scoring import WeightedScorer, PriorityScorer, UrgencyScorer, Score\n\n\ndef test_priority_scorer():\n    \"\"\"Test priority-based scoring.\"\"\"\n    scorer = PriorityScorer()\n    \n    ticket = Ticket(\n        ticket_id=\"TKT-001\",\n        title=\"Test ticket\",\n        description=\"Test description\",\n        requester_email=\"test@example.com\",\n        category=Category.GENERAL,\n        priority=Priority.CRITICAL,\n    )\n    \n    score = scorer.score(ticket)\n    assert score.total == 10.0\n    assert score.normalized == 1.0\n\n\ndef test_weighted_scorer_normalization():\n    \"\"\"Test weighted scorer with normalization.\"\"\"\n    def scorer1(ticket):\n        return 5.0\n    \n    def scorer2(ticket):\n        return 10.0\n    \n    scorer = WeightedScorer(\n        scorers={\"s1\": scorer1, \"s2\": scorer2},\n        weights={\"s1\": 0.6, \"s2\": 0.4},\n        normalize=True,\n    )\n    \n    ticket = Ticket(\n        ticket_id=\"TKT-001\",\n        title=\"Test ticket\",\n        description=\"Test description\",\n        requester_email=\"test@example.com\",\n        category=Category.GENERAL,\n    )\n    \n    score = scorer.score(ticket)\n    # Weighted sum: 5.0 * 0.6 + 10.0 * 0.4 = 3.0 + 4.0 = 7.0\n    # Normalized: 7.0 / (0.6 + 0.4) = 7.0 / 1.0 = 7.0\n    assert score.total == 7.0\n    assert score.normalized == 7.0\n\n\ndef test_weighted_scorer_zero_weights_bug():\n    \"\"\"\n    Test that exposes divide-by-zero bug in normalization.\n    \n    BUG: When sum of weights is zero, normalization divides by zero.\n    \"\"\"\n    def scorer1(ticket):\n        return 5.0\n    \n    scorer = WeightedScorer(\n        scorers={\"s1\": scorer1},\n        weights={\"s1\": 0.0},  # Zero weight\n        normalize=True,\n    )\n    \n    ticket = Ticket(\n        ticket_id=\"TKT-001\",\n        title=\"Test ticket\",\n        description=\"Test description\",\n        requester_email=\"test@example.com\",\n        category=Category.GENERAL,\n    )\n    \n    # BUG: This will cause divide-by-zero or return incorrect normalized value\n    score = scorer.score(ticket)\n    \n    # Should handle zero weights gracefully\n    assert score.normalized is not None\n    assert not (isinstance(score.normalized, float) and (score.normalized != score.normalized))  # Not NaN\n\n\ndef test_weighted_scorer_empty_weights_bug():\n    \"\"\"\n    Test that exposes bug with empty weights dictionary.\n    \n    BUG: If weights dict is empty but scorers exist, normalization fails.\n    \"\"\"\n    def scorer1(ticket):\n        return 5.0\n    \n    scorer = WeightedScorer(\n        scorers={\"s1\": scorer1},\n        weights={},  # Empty weights\n        normalize=True,\n    )\n    \n    ticket = Ticket(\n        ticket_id=\"TKT-001\",\n        title=\"Test ticket\",\n        description=\"Test description\",\n        requester_email=\"test@example.com\",\n        category=Category.GENERAL,\n    )\n    \n    # BUG: This may fail or return incorrect values\n    score = scorer.score(ticket)\n    \n    # Should handle empty weights - either use default weights or skip normalization\n    assert score.total is not None\n    # Normalized should be handled gracefully\n    if score.normalized is not None:\n        assert isinstance(score.normalized, float)\n\n\ndef test_weighted_scorer_mismatched_weights():\n    \"\"\"Test scorer with mismatched weights.\"\"\"\n    def scorer1(ticket):\n        return 5.0\n    \n    def scorer2(ticket):\n        return 10.0\n    \n    # Weights only for scorer1\n    scorer = WeightedScorer(\n        scorers={\"s1\": scorer1, \"s2\": scorer2},\n        weights={\"s1\": 0.6},  # Missing weight for s2\n        normalize=True,\n    )\n    \n    ticket = Ticket(\n        ticket_id=\"TKT-001\",\n        title=\"Test ticket\",\n        description=\"Test description\",\n        requester_email=\"test@example.com\",\n        category=Category.GENERAL,\n    )\n    \n    score = scorer.score(ticket)\n    # s1: 5.0 * 0.6 = 3.0\n    # s2: 10.0 * 1.0 (default) = 10.0\n    # Total: 13.0\n    # Normalized: 13.0 / (0.6 + 1.0) = 13.0 / 1.6 = 8.125\n    assert score.total == 13.0\n    assert abs(score.normalized - 8.125) < 0.01\n\n\ndef test_urgency_scorer():\n    \"\"\"Test urgency keyword scoring.\"\"\"\n    scorer = UrgencyScorer()\n    \n    ticket = Ticket(\n        ticket_id=\"TKT-001\",\n        title=\"Urgent: System down\",\n        description=\"Critical error occurred\",\n        requester_email=\"test@example.com\",\n        category=Category.GENERAL,\n    )\n    \n    score = scorer.score(ticket)\n    # Should find \"urgent\" and \"critical\" keywords\n    assert score.total > 0\n    assert score.normalized is not None\n\n\n\n\n===== END FIXTURE CODEBASE =====\n\nReview the codebase in fixtures/helpdesk_ai/ and identify any bugs or issues. The complete codebase will be provided in the expanded input.",
  "steps": [
    {
      "name": "planner",
      "instruction": "Analyze the codebase structure and plan an approach to identify bugs and issues."
    },
    {
      "name": "executor",
      "instruction": "Execute the analysis plan and identify specific bugs or issues in the codebase."
    },
    {
      "name": "verifier",
      "instruction": "Verify the identified issues are valid bugs and provide a summary of findings."
    }
  ]
}